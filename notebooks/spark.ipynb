{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://xdss-public-datasets/demos/taxi_1m.csv to ../datasets/taxi_1m.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://xdss-public-datasets/demos/taxi_1m.csv ../datasets/taxi_1m.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import sql, SparkConf, SparkContext\n",
    "import pyspark.sql.functions as f\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import time\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "benchmarks = {}\n",
    "\n",
    "def benchmark(f, name, df, repetitions=1, **kwargs):\n",
    "    times = []\n",
    "    count = 0\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        times.append(time.time()-start_time)\n",
    "        count+=1\n",
    "    benchmarks[name] = np.mean(times)/count\n",
    "    return benchmarks[name]\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results\n",
    "\n",
    "conf = SparkConf().setAppName('Read_CSV')\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = sql.SQLContext(sc)\n",
    "data_path = '../datasets/taxi_1m.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    return sqlContext.read.csv(data_path, sep = ',', header = 'True', inferSchema = 'true')\n",
    "    \n",
    "def mean(df):\n",
    "    return df.select(f.mean('fare_amount')).collect()\n",
    "    \n",
    "def standard_deviation(df):\n",
    "    return df.select(f.stddev('fare_amount')).collect()\n",
    "\n",
    "def sum_columns(df):\n",
    "    return df.select(df['fare_amount'] + df['passenger_count']).collect()\n",
    "\n",
    "def product_columns(df):\n",
    "    return df.select(df['fare_amount'] * df['passenger_count']).collect() \n",
    "\n",
    "def complicated_arithmetic_operation(df):\n",
    "    theta_1 = df['pickup_longitude']\n",
    "    phi_1 = df['pickup_latitude']\n",
    "    theta_2 = df['dropoff_longitude']\n",
    "    phi_2 = df['dropoff_latitude']\n",
    "    temp = ((np.cos(df.select(theta_1).collect())*np.pi/180)*np.cos(df.select(theta_2).collect())*np.pi/180) \\\n",
    "            * (np.sin((df.select(phi_2-phi_1).collect()))/2*np.pi/180)**2\n",
    "\n",
    "    return 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "\n",
    "def value_counts(df):\n",
    "    return df.select('fare_amount').distinct().collect()\n",
    "\n",
    "def groupby_statistics(df):\n",
    "    return df.groupby('pickup_hour').agg(\n",
    "        f.mean('fare_amount'),\n",
    "        f.stddev('fare_amount'),\n",
    "        f.mean('tip_amount'),\n",
    "        f.stddev('tip_amount'))\n",
    "\n",
    "def join(df, other):\n",
    "    return df.join(other, on = 'pickup_hour')\n",
    "    \n",
    "\n",
    "def filter_data(df):\n",
    "    long_min = -74.05\n",
    "    long_max = -73.75\n",
    "    lat_min = 40.58\n",
    "    lat_max = 40.90\n",
    "\n",
    "    expr_filter = (df.pickup_longitude > long_min)  & (df.pickup_longitude < long_max) & \\\n",
    "              (df.pickup_latitude > lat_min)    & (df.pickup_latitude < lat_max) & \\\n",
    "              (df.dropoff_longitude > long_min) & (df.dropoff_longitude < long_max) & \\\n",
    "              (df.dropoff_latitude > lat_min)   & (df.dropoff_latitude < lat_max)\n",
    "    return df.filter(expr_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = read_file()\n",
    "data = data.withColumn('pickup_hour', sql.functions.split(data['pickup_datetime'], ' ').getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark\n",
    "benchmark(mean, 'mean', data, repetitions=10)\n",
    "benchmark(standard_deviation,'standard deviation', data, repetitions=10)\n",
    "benchmark(sum_columns, 'sum columns', data, repetitions=10)\n",
    "benchmark(product_columns, 'product columns', data, repetitions=10)\n",
    "benchmark(complicated_arithmetic_operation, 'complicated arithmetic operation', data, repetitions=10)\n",
    "benchmark(value_counts, 'value counts', data, repetitions=10)\n",
    "benchmark(groupby_statistics, 'groupby statistics', data, repetitions=10)\n",
    "benchmark(filter_data, 'filter', data, repetitions=10)\n",
    "gc.collect()\n",
    "\n",
    "gp = groupby_statistics(data)\n",
    "benchmark(join, 'join', data, repetitions=10, other=gp)\n",
    "print(f\"Done benchmarks on all data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd = filter_data(data)\n",
    "\n",
    "del data\n",
    "del gp\n",
    "\n",
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark\n",
    "benchmark(mean, 'filtered mean', filterd, repetitions=10)\n",
    "benchmark(standard_deviation,'filtered standard deviation', filterd, repetitions=10)\n",
    "benchmark(sum_columns, 'filtered sum columns', filterd, repetitions=10)\n",
    "benchmark(product_columns, 'filtered product_columns', filterd, repetitions=10)\n",
    "benchmark(complicated_arithmetic_operation, 'filtered complicated arithmetic_operation', filterd, repetitions=10)\n",
    "benchmark(value_counts, 'filtered value_counts', filterd, repetitions=10)\n",
    "benchmark(groupby_statistics, 'filtered groupby statistics', filterd, repetitions=10)\n",
    "\n",
    "gp = filterd.groupby(by='pickup_hour').agg({'fare_amount': ['mean', 'std'], \n",
    "                                        'tip_amount': ['mean', 'std']\n",
    "                                        })\n",
    "benchmark(join, 'filtered join', filterd, repetitions=10, other=gp)\n",
    "print(f\"Done benchmarks on all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'spark'\n",
    "results = get_results(benchmarks, name)\n",
    "results.to_csv(f\"results/{name}_1m.csv\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp  ../results/spark_1m.csv s3://vaex-sagemaker-demo/benchmarks/spark_1m_results.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
