{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%capture\n",
    "!aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_parquet ../datasets/taxi_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T22:20:36.781138Z",
     "start_time": "2020-01-09T22:20:33.299390Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from src.benchmarks_utils import benchmark, get_results\n",
    "from src.spark_utils import *\n",
    "from src.config import repetitions\n",
    "\n",
    "\n",
    "name = 'spark'\n",
    "data_path = '../datasets/taxi_parquet/'\n",
    "results_path = f\"../results/{name}_1m.csv\"\n",
    "benchmarks = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T22:20:42.001458Z",
     "start_time": "2020-01-09T22:20:36.783706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1173057928 with 19 columns\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = read_file(data_path=data_path)\n",
    "data = data.withColumn('pickup_hour', sql.functions.split(data['pickup_datetime'], ' ').getItem(1))\n",
    "print(f\"size: {data.count()} with {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned 272 mb\n",
      "Done benchmarks on all data\n",
      "Prepare filtered data and deleted 325 MB\n",
      "Done benchmarks on filterd data\n"
     ]
    }
   ],
   "source": [
    "benchmarks['read_file']= benchmark(read_file, df=data, data_path=data_path, repetitions=repetitions)\n",
    "benchmarks['mean']= benchmark(mean, data, repetitions=repetitions)\n",
    "benchmarks['standard deviation']= benchmark(standard_deviation, data, repetitions=repetitions)\n",
    "benchmarks['sum columns']= benchmark(sum_columns, data, repetitions=repetitions)\n",
    "benchmarks['product columns']= benchmark(product_columns, data, repetitions=repetitions)\n",
    "benchmarks['arithmetic operation']= benchmark(complicated_arithmetic_operation, data, repetitions=repetitions)\n",
    "benchmarks['value counts']= benchmark(value_counts, data, repetitions=repetitions)\n",
    "benchmarks['groupby statistics']= benchmark(groupby_statistics, data, repetitions=repetitions)\n",
    "benchmarks['filter']= benchmark(filter_data, data, repetitions=repetitions)\n",
    "print(f\"cleaned {gc.collect()} mb\")\n",
    "benchmarks['join'] = benchmark(join, data, repetitions=repetitions, other=groupby_statistics(data))\n",
    "print(f\"Done benchmarks on all data\")\n",
    "\n",
    "# filtered\n",
    "filterd = filter_data(data)\n",
    "del data\n",
    "\n",
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")\n",
    "benchmarks['filtered mean'] = benchmark(mean, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered standard deviation'] = benchmark(standard_deviation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered sum columns'] = benchmark(sum_columns , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered product_columns'] = benchmark(product_columns , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered complicated arithmetic operation'] = benchmark(complicated_arithmetic_operation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered value counts'] = benchmark(value_counts, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered groupby statistics'] = benchmark(groupby_statistics, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered join'] = benchmark(join, filterd, repetitions=repetitions, other=groupby_statistics(filterd))\n",
    "print(f\"Done benchmarks on filterd data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>read_file</th>\n",
       "      <td>0.116327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.933656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard deviation</th>\n",
       "      <td>6.485325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum columns</th>\n",
       "      <td>4.009585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product columns</th>\n",
       "      <td>4.255570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       spark\n",
       "read_file           0.116327\n",
       "mean                2.933656\n",
       "standard deviation  6.485325\n",
       "sum columns         4.009585\n",
       "product columns     4.255570"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_results(benchmarks, name)\n",
    "results.to_csv(results_path)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 662 Bytes/662 Bytes (11.0 KiB/s) with 1 file(s) remaining\r",
      "upload: ../results/spark_1m.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1m_results.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp  ../results/spark_1m.csv s3://vaex-sagemaker-demo/benchmarks/spark_1m_results.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
