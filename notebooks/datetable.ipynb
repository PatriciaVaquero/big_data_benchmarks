{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:06.690430Z",
     "start_time": "2020-01-13T14:20:54.182849Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install jupyter_contrib_nbextensions\n",
    "pip install jupyter_nbextensions_configurator\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "jupyter nbextension enable codefolding/main\n",
    "jupyter nbextension enable scratchpad/main\n",
    "jupyter nbextension enable execute_time/ExecuteTime\n",
    "jupyter nbextension enable autosavetime/main\n",
    "pip install -U pip dask numpy fsspec>=0.3.3 tqdm pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T11:56:42.427681Z",
     "start_time": "2020-02-28T11:56:28.583270Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pip datatable vaex-core vaex-hdf5 vaex-arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:06:07.993674Z",
     "start_time": "2020-02-28T11:58:32.539834Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!aws s3 cp s3://xdss-public-datasets/demos/taxi_1B.hdf5 datasets/taxi_1B.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:33:16.827540Z",
     "start_time": "2020-02-28T12:33:16.086148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for 1 repetitions for join and groupby and 5 repetitions for statistics\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "instance_type = 'c5d2xlarge' # change this\n",
    "results_bucket = f\"s3://vaex-sagemaker-demo/benchmarks\" # change this\n",
    "\n",
    "name = 'datatable'\n",
    "data_path = 'datasets/taxi_1B.hdf5'\n",
    "output_file = f'{name}_{instance_type}_results.csv'\n",
    "results_path = f\"results/{output_file}\"\n",
    "results_bucket = f\"{results_bucket}/{output_file}\" \n",
    "benchmarks = {}\n",
    "single_repetition = 1\n",
    "statistic_repetition = 5\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results\n",
    "\n",
    "def persist():\n",
    "    gc.collect()\n",
    "    get_results(benchmarks, name).to_csv(results_path)\n",
    "    os.system(f\"aws s3 cp {results_path} {results_bucket}\")\n",
    "    \n",
    "def benchmark(f, df, name, repetitions=1, **kwargs):\n",
    "    times = []\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        times.append(time.time()-start_time)\n",
    "    benchmarks[name] = np.mean(times)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks[name]}\")\n",
    "    return benchmarks[name]\n",
    "\n",
    "\n",
    "!mkdir -p results\n",
    "!mkdir -p datasets\n",
    "print(f\"test for {single_repetition} repetitions for join and groupby and {statistic_repetition} repetitions for statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:33:18.416605Z",
     "start_time": "2020-02-28T12:33:17.297212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .boolean { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .integer { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .string  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import vaex\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "from datatable import f, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:33:21.295252Z",
     "start_time": "2020-02-28T12:33:21.282635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1173057927 with 14 columns\n"
     ]
    }
   ],
   "source": [
    "def read_file(data=None):\n",
    "    vdf = vaex.open(data_path)\n",
    "    columns = {}\n",
    "    for name in vdf.get_column_names():\n",
    "        data = vdf.columns[name]\n",
    "        if data.dtype == str:\n",
    "            pass  # skip strings\n",
    "        elif data.dtype.kind == 'f':\n",
    "            # datatable is picky about <f4 format\n",
    "            columns[name] = data.view(np.float32)\n",
    "        elif data.dtype.kind == 'i':\n",
    "            columns[name] = data\n",
    "        else:\n",
    "            pass  # ignore non int and float\n",
    "    return dt.Frame(**columns)\n",
    "\n",
    "# Load data\n",
    "data = read_file(data=None)\n",
    "print(f\"size: {data.shape[0]} with {data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:33:24.259691Z",
     "start_time": "2020-02-28T12:33:23.586277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_file took: 0.0057408809661865234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0057408809661865234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(read_file, df=data, name='read_file', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:33:24.804659Z",
     "start_time": "2020-02-28T12:33:24.261393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count took: 1.7642974853515626e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7642974853515626e-06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count(df=None):\n",
    "    return df.shape[0]\n",
    "\n",
    "benchmark(count, df=data, name='count', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:34:09.378487Z",
     "start_time": "2020-02-28T12:33:24.806272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean took: 8.807757329940795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.807757329940795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean(df):\n",
    "    return df[:, dt.mean(dt.f.fare_amount)]\n",
    "\n",
    "benchmark(mean, df=data, name='mean', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:34:49.489720Z",
     "start_time": "2020-02-28T12:34:09.380164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation took: 7.904828929901123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.904828929901123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_deviation(df):\n",
    "    return df[:, dt.sd(dt.f.fare_amount)]\n",
    "\n",
    "benchmark(standard_deviation, df=data, name='standard deviation', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the time when using two columns, we can't return the response since it will get into memroy and break, so we run a mean calculation on it, and then remove the time it took to run the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:36:15.919821Z",
     "start_time": "2020-02-28T12:34:49.491446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum columns mean took: 17.174331140518188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.174331140518188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_sum(df):\n",
    "    return df[:, dt.mean(f.fare_amount + f.trip_distance)]\n",
    "\n",
    "benchmark(mean_of_sum, df=data, name='sum columns mean', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:36:16.479711Z",
     "start_time": "2020-02-28T12:36:15.921482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum columns took: 2.9754638671875e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9754638671875e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_columns(df):\n",
    "    return df[:, f.fare_amount + f.trip_distance]\n",
    "\n",
    "benchmark(sum_columns, df=data, name='sum columns', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:37:30.121878Z",
     "start_time": "2020-02-28T12:36:16.481249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product columns mean took: 14.600020599365234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.600020599365234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_product(df):\n",
    "    return df[:, dt.mean(f.fare_amount * f.trip_distance)]\n",
    "\n",
    "benchmark(mean_of_product, df=data, name='product columns mean', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:37:30.668291Z",
     "start_time": "2020-02-28T12:37:30.123492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product columns took: 2.93731689453125e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.93731689453125e-05"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def product(df):\n",
    "    return df[:, f.fare_amount * f.trip_distance]\n",
    "\n",
    "benchmark(product, df=data, name='product columns', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T12:37:30.673550Z",
     "start_time": "2020-02-28T12:37:30.669886Z"
    }
   },
   "outputs": [],
   "source": [
    "from datatable import math\n",
    "# Memorry crash\n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = f.pickup_longitude\n",
    "    phi_1 = f.pickup_latitude\n",
    "    theta_2 = f.dropoff_longitude\n",
    "    phi_2 = f.dropoff_latitude\n",
    "    temp = (math.sin((theta_2-theta_1)/2*math.pi/180)**2\n",
    "           + math.cos(theta_1*math.pi/180)*math.cos(theta_2*math.pi/180) * math.sin((phi_2-phi_1)/2*math.pi/180)**2)\n",
    "    expr = 2 * math.atan2(math.sqrt(temp), math.sqrt(1-temp))\n",
    "    return df[:, dt.mean(expr)]\n",
    "\n",
    "# benchmark(mean_of_complicated_arithmetic_operation, df=data, name='arithmetic operation mean', repetitions=statistic_repetition)\n",
    "benchmarks['arithmetic operation'] =  np.nan\n",
    "benchmarks['arithmetic operation mean'] =  np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:29.034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Memorry crash\n",
    "from datatable import f, count\n",
    "\n",
    "def value_counts(df):\n",
    "    return df[:,count(f.passenger_count),'passenger_count']\n",
    "\n",
    "# benchmark(value_counts, df=data, name='value counts', repetitions=statistic_repetition)\n",
    "benchmarks['value counts'] =  np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:31.464Z"
    }
   },
   "outputs": [],
   "source": [
    "def groupby_statistics(df):\n",
    "    aggs = {\n",
    "            'fare_amount_mean': dt.mean(f.fare_amount),\n",
    "            'fare_amount_std': dt.sd(f.fare_amount),\n",
    "            'tip_amount_mean': dt.mean(f.tip_amount),\n",
    "            'tip_amount_std': dt.sd(f.tip_amount),\n",
    "        }\n",
    "    return df[:, aggs, dt.by(f.passenger_count)]\n",
    "\n",
    "benchmark(groupby_statistics, df=data, name='groupby statistics', repetitions=single_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:33.140Z"
    }
   },
   "outputs": [],
   "source": [
    "other = groupby_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:33.376Z"
    }
   },
   "outputs": [],
   "source": [
    "def join(df, other):\n",
    "    # like vaex and dask, no precomputed index\n",
    "    other.key = 'passenger_count'\n",
    "    return df[:,:,dt.join(other)]\n",
    "\n",
    "benchmark(join, data, name='join', repetitions=single_repetition, other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:33.691Z"
    }
   },
   "outputs": [],
   "source": [
    "def join_count(df, other):\n",
    "    # like vaex and dask, no precomputed index\n",
    "    other.key = 'passenger_count'\n",
    "    return df[:,:,dt.join(other)].shape[0]\n",
    "\n",
    "benchmark(join_count, data, name='join count', repetitions=single_repetition, other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:35.683Z"
    }
   },
   "outputs": [],
   "source": [
    "For the entire dataaset, non of this runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is not build to run on filter data like you would normally, so we will apply the same strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:36.369Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:36.639Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    expr_filter = (f.pickup_longitude > long_min)  & (f.pickup_longitude < long_max) & \\\n",
    "              (f.pickup_latitude > lat_min)    & (f.pickup_latitude < lat_max) & \\\n",
    "              (f.dropoff_longitude > long_min) & (f.dropoff_longitude < long_max) & \\\n",
    "              (f.dropoff_latitude > lat_min)   & (f.dropoff_latitude < lat_max)\n",
    "    return df[expr_filter,:]\n",
    "\n",
    "benchmark(filter_data, data, name='filter data', repetitions=single_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T12:33:37.134Z"
    }
   },
   "outputs": [],
   "source": [
    "filterd = filter_data(data)\n",
    "\n",
    "del data\n",
    "print(f\"cleaned {gc.collect()} mb\")\n",
    "\n",
    "benchmark(filter_data, filterd, name='filterd count', repetitions=statistic_repetition)\n",
    "benchmark(mean, filterd, name='filterd mean', repetitions=statistic_repetition)\n",
    "benchmark(standard_deviation, filterd, name='filtered standard deviation', repetitions=statistic_repetition)\n",
    "benchmark(mean_of_sum, filterd, name ='filtered sum columns mean', repetitions=statistic_repetition)\n",
    "benchmark(sum_columns, df=filterd, name='filtered sum columns', repetitions=statistic_repetition)\n",
    "benchmark(mean_of_product, filterd, name ='filterd product columns mean', repetitions=statistic_repetition)\n",
    "benchmark(product, df=filterd, name='filterd product columns', repetitions=statistic_repetition)\n",
    "benchmark(mean_of_complicated_arithmetic_operation, filterd, name='filterd arithmetic operation mean', repetitions=statistic_repetition)\n",
    "benchmarks['filterd arithmetic operation'] =  np.nan\n",
    "benchmark(value_counts, filterd, name ='filtered value counts', repetitions=statistic_repetition)\n",
    "benchmark(groupby_statistics, filterd, name='filtered groupby statistics', repetitions=single_repetition)\n",
    "other = groupby_statistics(filterd)\n",
    "benchmark(join, filterd, name ='filtered join', repetitions=single_repetition, other=other)\n",
    "benchmark(join_count, filterd, name='filtered join count', repetitions=single_repetition, other=other)\n",
    "print('datatable!')\n",
    "print(get_results(benchmarks,'datatable'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
