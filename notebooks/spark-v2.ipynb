{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:06.690430Z",
     "start_time": "2020-01-13T14:20:54.182849Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install jupyter_contrib_nbextensions\n",
    "pip install jupyter_nbextensions_configurator\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "jupyter nbextension enable codefolding/main\n",
    "jupyter nbextension enable scratchpad/main\n",
    "jupyter nbextension enable execute_time/ExecuteTime\n",
    "jupyter nbextension enable autosavetime/main\n",
    "pip install -U pip dask numpy fsspec>=0.3.3 tqdm pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_parquet ../datasets/taxi_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:54:02.624333Z",
     "start_time": "2020-01-23T13:54:01.107335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for 1 repetitions\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from src.config import repetitions\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "instance_type = 'mlm52xlarge'\n",
    "name = 'spark'\n",
    "data_path = '../datasets/taxi_parquet/'\n",
    "instance_type = 'mlm52xlarge'\n",
    "results_path = f\"../results/{name}_1b_{instance_type}.csv\"\n",
    "benchmarks = {}\n",
    "print(f\"test for {repetitions} repetitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T13:10:49.300827Z",
     "start_time": "2020-01-25T13:10:49.296639Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results\n",
    "\n",
    "def persist():\n",
    "    get_results(benchmarks, name).to_csv(results_path)\n",
    "    !aws s3 cp  ../results/spark_1b_mlm52xlarge.csv s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv \n",
    "    \n",
    "def benchmark(f, df, name, repetitions=1, **kwargs):\n",
    "    times = []\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        times.append(time.time()-start_time)\n",
    "    benchmarks[name] = np.mean(times)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks[name]}\")\n",
    "    return benchmarks[name]\n",
    "\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sql, SparkConf, SparkContext\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "conf = SparkConf().setAppName('Benchmarks')\n",
    "conf.setExecutorEnv('spark.executor.memory', '2g')\n",
    "conf.setExecutorEnv('spark.driver.memory', '30g')\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = sql.SQLContext(sc)\n",
    "\n",
    "data = sqlContext.read.parquet(data_path)\n",
    "print(f\"size: {len(data)} with {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read/ open\n",
    "def open_file(df=None, data_path=None):\n",
    "    return sqlContext.read.parquet(data_path)\n",
    "\n",
    "key = open_file\n",
    "f= open_file\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df=None):\n",
    "    return df.count()\n",
    "\n",
    "key = 'count'\n",
    "f = count\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(df):\n",
    "    return df.select(f.mean('fare_amount')).collect()\n",
    "\n",
    "key = 'mean'\n",
    "f = mean\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_deviation(df):\n",
    "    return df.select(f.stddev('fare_amount')).collect()\n",
    "\n",
    "key = 'standard deviation'\n",
    "f = standard_deviation\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other techonlogies, vaex can return columns, or subset of values to explore lazely, \n",
    "but becouse many of the other tecnologies crashed at this point, we return a scalar instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_sum(df):\n",
    "    return df.select(f.mean(df['fare_amount'] + df['trip_distance'])).collect()\n",
    "\n",
    "key = 'sum columns mean'\n",
    "f = mean_of_sum\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)\n",
    "benchmarks['sum columns'] =  benchmarks['sum columns mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:46:15.298677Z",
     "start_time": "2020-01-25T12:45:58.666423Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_of_product(df):\n",
    "    return df.select(f.mean(df['fare_amount'] * df['trip_distance'])).collect()\n",
    "\n",
    "key = 'product columns mean'\n",
    "f = mean_of_product\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)\n",
    "benchmarks['product columns'] =  benchmarks['product columns mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:49:16.297072Z",
     "start_time": "2020-01-25T12:46:15.300207Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df['pickup_longitude']\n",
    "    phi_1 = df['pickup_latitude']\n",
    "    theta_2 = df['dropoff_longitude']\n",
    "    phi_2 = df['dropoff_latitude']\n",
    "    temp = (f.cos(theta_1)*np.pi/180) * (f.cos(theta_2)*np.pi/180) * (f.sin(phi_2-phi_1)/2*np.pi/180)**2\n",
    "    expression = 2 * f.atan2(f.sqrt(temp), f.sqrt(1-temp))\n",
    "    return df.select(f.mean(expression)).collect()\n",
    "\n",
    "key = 'arithmetic operation mean'\n",
    "f  = mean_of_complicated_arithmetic_operation\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)\n",
    "benchmarks['arithmetic operation'] =  benchmarks['arithmetic operation mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:49:30.727079Z",
     "start_time": "2020-01-25T12:49:16.298605Z"
    }
   },
   "outputs": [],
   "source": [
    "def value_counts(df):\n",
    "    return df.select('fare_amount').distinct().collect()\n",
    "\n",
    "key = 'value counts'\n",
    "f  = value_counts\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-25T12:51:30.334Z"
    },
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "def groupby_statistics(df):\n",
    "    ret = df.groupby('passenger_count').agg(\n",
    "        f.mean('fare_amount'),\n",
    "        f.stddev('fare_amount'),\n",
    "        f.mean('tip_amount'),\n",
    "        f.stddev('tip_amount')\n",
    "    )\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "\n",
    "key = 'groupby statistics'\n",
    "f = groupby_statistics\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = groupby_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-25T13:12:11.561Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def join(df, other):\n",
    "    ret = df.join(other, on = 'passenger_count')\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "\n",
    "key = 'join'\n",
    "f = join\n",
    "benchmark(f, data, name=key, repetitions=repetitions, other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def join_count(df, other):\n",
    "    return df.join(other, on = 'passenger_count').count()\n",
    "\n",
    "key = 'join count'\n",
    "f = join_count\n",
    "benchmark(f, data, name=key, repetitions=repetitions, other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-25T13:12:15.595Z"
    }
   },
   "outputs": [],
   "source": [
    "persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is not build to run on filter data like you would normally, so we will apply the same strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-23T13:55:12.933Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    expr_filter = (df.pickup_longitude > long_min)  & (df.pickup_longitude < long_max) & \\\n",
    "              (df.pickup_latitude > lat_min)    & (df.pickup_latitude < lat_max) & \\\n",
    "              (df.dropoff_longitude > long_min) & (df.dropoff_longitude < long_max) & \\\n",
    "              (df.dropoff_latitude > lat_min)   & (df.dropoff_latitude < lat_max)\n",
    "    ret = df[expr_filter]\n",
    "    ret.take(3) # evaluate the filter\n",
    "    return ret\n",
    "\n",
    "key = 'filter data'\n",
    "f = filter_data\n",
    "benchmark(f, data, name=key, repetitions=repetitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd = filter_data(data)\n",
    "\n",
    "del data\n",
    "print(f\"cleaned {gc.collect()} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(filter_data, filterd, name='filterd count', repetitions=repetitions)\n",
    "benchmark(mean, filterd, name='filterd mean', repetitions=repetitions)\n",
    "benchmark(standard_deviation, filterd, name='filtered standard deviation', repetitions=repetitions)\n",
    "benchmark(mean_of_sum, filterd, name ='filtered sum columns mean', repetitions=repetitions)\n",
    "benchmarks['filtered sum columns'] =  benchmarks['filtered sum columns mean'] - benchmarks['filterd mean']\n",
    "benchmark(mean_of_product, filterd, name ='filterd product columns mean', repetitions=repetitions)\n",
    "benchmarks['filterd product columns'] = benchmarks['filterd product columns mean'] - benchmarks['filterd mean']\n",
    "benchmark(mean_of_complicated_arithmetic_operation, filterd, name='filterd arithmetic operation mean', repetitions=repetitions)\n",
    "benchmarks['filterd arithmetic operation'] =  benchmarks['filterd arithmetic operation mean'] - benchmarks['filterd mean']\n",
    "benchmark(value_counts, filterd, name ='filtered value counts', repetitions=repetitions)\n",
    "benchmark(groupby_statistics, filterd, name='filtered groupby statistics', repetitions=repetitions)\n",
    "other = groupby_statistics(data)\n",
    "benchmarks['filtered join'] = -1\n",
    "benchmarks['filtered join count'] = benchmark(join_count, filterd, repetitions=repetitions, other=other)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
