{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pip dask numpy fsspec>=0.3.3\n",
    "# !aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_1m.csv ../datasets/taxi_1m.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import time\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "benchmarks = {}\n",
    "\n",
    "def benchmark(f, name, df, repetitions=1, **kwargs):\n",
    "    times = []\n",
    "    count = 0\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        times.append(time.time()-start_time)\n",
    "        count+=1\n",
    "    benchmarks[name] = np.mean(times)/count\n",
    "    return benchmarks[name]\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results\n",
    "\n",
    "data_path = '../datasets/taxi_1m.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    return dd.read_csv(data_path)\n",
    "    \n",
    "def mean(df):\n",
    "    return df.fare_amount.mean().compute()\n",
    "    \n",
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std().compute()\n",
    "\n",
    "def sum_columns(df):\n",
    "    return dd.compute(df.fare_amount + df.passenger_count) \n",
    "\n",
    "def product_columns(df):\n",
    "    return dd.compute(df.fare_amount * df.passenger_count)\n",
    "\n",
    "def complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.pickup_longitude\n",
    "    phi_1 = df.pickup_latitude\n",
    "    theta_2 = df.dropoff_longitude\n",
    "    phi_2 = df.dropoff_latitude\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    return 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "\n",
    "def value_counts(df):\n",
    "    return df.fare_amount.value_counts().compute()\n",
    "\n",
    "def groupby_statistics(df):\n",
    "    return df.groupby(by='pickup_hour').agg({'fare_amount': ['mean', 'std'], \n",
    "                                               'tip_amount': ['mean', 'std']\n",
    "                                              })\n",
    "def join(df, other):\n",
    "    return df.join(other=gp, on = 'pickup_hour', rsuffix = '_right')\n",
    "    \n",
    "\n",
    "def filter_data(df):\n",
    "    long_min = -74.05\n",
    "    long_max = -73.75\n",
    "    lat_min = 40.58\n",
    "    lat_max = 40.90\n",
    "\n",
    "    expr_filter = (data.pickup_longitude > long_min)  & (data.pickup_longitude < long_max) & \\\n",
    "                  (data.pickup_latitude > lat_min)    & (data.pickup_latitude < lat_max) & \\\n",
    "                  (data.dropoff_longitude > long_min) & (data.dropoff_longitude < long_max) & \\\n",
    "                  (data.dropoff_latitude > lat_min)   & (data.dropoff_latitude < lat_max)\n",
    "    return df[expr_filter]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = dd.read_csv(data_path)\n",
    "data.pickup_datetime = dd.to_datetime(data.pickup_datetime)\n",
    "data['pickup_hour'] = data.pickup_datetime.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done benchmarks on all data\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "benchmark(mean, 'mean', data, repetitions=10)\n",
    "benchmark(standard_deviation,'standard deviation', data, repetitions=10)\n",
    "benchmark(sum_columns, 'sum columns', data, repetitions=10)\n",
    "benchmark(product_columns, 'product columns', data, repetitions=10)\n",
    "benchmark(complicated_arithmetic_operation, 'complicated arithmetic operation', data, repetitions=10)\n",
    "benchmark(value_counts, 'value counts', data, repetitions=10)\n",
    "benchmark(groupby_statistics, 'groupby statistics', data, repetitions=10)\n",
    "benchmark(filter_data, 'filter', data, repetitions=10)\n",
    "gc.collect()\n",
    "\n",
    "gp = groupby_statistics(data)\n",
    "benchmark(join, 'join', data, repetitions=10, other=gp)\n",
    "print(f\"Done benchmarks on all data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare filtered data and deleted 77 MB\n"
     ]
    }
   ],
   "source": [
    "filterd = filter_data(data)\n",
    "del data\n",
    "del gp\n",
    "\n",
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done benchmarks on filterd data\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "benchmark(mean, 'filtered mean', filterd, repetitions=10)\n",
    "benchmark(standard_deviation,'filtered standard deviation', filterd, repetitions=10)\n",
    "benchmark(sum_columns, 'filtered sum columns', filterd, repetitions=10)\n",
    "benchmark(product_columns, 'filtered product_columns', filterd, repetitions=10)\n",
    "benchmark(complicated_arithmetic_operation, 'filtered complicated arithmetic_operation', filterd, repetitions=10)\n",
    "benchmark(value_counts, 'filtered value_counts', filterd, repetitions=10)\n",
    "benchmark(groupby_statistics, 'filtered groupby statistics', filterd, repetitions=10)\n",
    "\n",
    "gp = groupby_statistics(filterd)\n",
    "benchmark(join, 'filtered join', filterd, repetitions=10, other=gp)\n",
    "print(f\"Done benchmarks on filterd data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.272893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard deviation</th>\n",
       "      <td>0.260367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum columns</th>\n",
       "      <td>0.256564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product columns</th>\n",
       "      <td>0.256770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complicated arithmetic operation</th>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      dask\n",
       "mean                              0.272893\n",
       "standard deviation                0.260367\n",
       "sum columns                       0.256564\n",
       "product columns                   0.256770\n",
       "complicated arithmetic operation  0.001890"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "name = 'dask'\n",
    "results = get_results(benchmarks, name)\n",
    "results.to_csv(f\"../results/{name}_1m.csv\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/dask_1m.csv to s3://vaex-sagemaker-demo/benchmarks/dask_1m_results.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp  ../results/dask_1m.csv s3://vaex-sagemaker-demo/benchmarks/dask_1m_results.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
