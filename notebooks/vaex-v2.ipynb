{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:06.690430Z",
     "start_time": "2020-01-13T14:20:54.182849Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install jupyter_contrib_nbextensions\n",
    "pip install jupyter_nbextensions_configurator\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "jupyter nbextension enable codefolding/main\n",
    "jupyter nbextension enable scratchpad/main\n",
    "jupyter nbextension enable execute_time/ExecuteTime\n",
    "jupyter nbextension enable autosavetime/main\n",
    "pip install -U pip dask numpy fsspec>=0.3.3 tqdm pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:54:01.055209Z",
     "start_time": "2020-01-23T13:53:59.104116Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install vaex-core vaex-hdf5\n",
    "!pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://xdss-public-datasets/demos/taxi_1B.hdf5 ../datasets/taxi_1B.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:54:02.624333Z",
     "start_time": "2020-01-23T13:54:01.107335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for 1 repetitions\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from src.config import repetitions\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "instace_type = 'mlm52xlarge'\n",
    "name = 'vaex'\n",
    "data_path = '../datasets/taxi_1B.hdf5'\n",
    "results_path = f\"../results/{name}_1b_{instace_type}.csv\"\n",
    "benchmarks = {}\n",
    "print(f\"test for {repetitions} repetitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T13:10:49.300827Z",
     "start_time": "2020-01-25T13:10:49.296639Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results\n",
    "\n",
    "def persist():\n",
    "    get_results(benchmarks, name).to_csv(results_path)\n",
    "    !aws s3 cp  ../results/vaex_1b_mlm52xlarge.csv s3://vaex-sagemaker-demo/benchmarks/vaex_1b_mlm52xlarge_results.csv \n",
    "    \n",
    "def benchmark(f, df, name, repetitions=1, **kwargs):\n",
    "    times = []\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        times.append(time.time()-start_time)\n",
    "    benchmarks[name] = np.mean(times)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks[name]}\")\n",
    "    return benchmarks[name]\n",
    "\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:54:52.429148Z",
     "start_time": "2020-01-23T13:54:02.625872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1173057928 with 18 columns\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = dd.read_parquet(data_path, engine='pyarrow')\n",
    "print(f\"size: {len(data)} with {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(df=None, data_path=None):\n",
    "    return vaex.open(data_path)\n",
    "\n",
    "key = 'read_file'\n",
    "f= open_file\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df=None):\n",
    "    return len(df)\n",
    "\n",
    "key = 'count'\n",
    "f = count\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(df):\n",
    "    return df.fare_amount.mean()\n",
    "\n",
    "key = 'mean'\n",
    "f = mean\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std()\n",
    "\n",
    "key = 'standard deviation'\n",
    "f = standard_deviation\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other techonlogies, vaex can return columns, or subset of values to explore lazely, \n",
    "but becouse many of the other tecnologies crashed at this point, we return a scalar instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_sum(df):\n",
    "    return (df.fare_amount + df.trip_distance).mean()\n",
    "\n",
    "key = 'sum columns mean'\n",
    "f = mean_of_sum\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)\n",
    "benchmarks['sum columns'] =  benchmarks['sum columns mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:46:15.298677Z",
     "start_time": "2020-01-25T12:45:58.666423Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_of_product(df):\n",
    "    return (df.fare_amount * df.trip_distance).mean()\n",
    "\n",
    "key = 'product columns mean'\n",
    "f = mean_of_product\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)\n",
    "benchmarks['product columns'] =  benchmarks['product columns mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:49:16.297072Z",
     "start_time": "2020-01-25T12:46:15.300207Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.pickup_longitude\n",
    "    phi_1 = df.pickup_latitude\n",
    "    theta_2 = df.dropoff_longitude\n",
    "    phi_2 = df.dropoff_latitude\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    df['complicated'] = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return df['complicated'].mean()\n",
    "\n",
    "key = 'arithmetic operation mean'\n",
    "f  = mean_of_complicated_arithmetic_operation\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)\n",
    "benchmarks['arithmetic operation'] =  benchmarks['arithmetic operation mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:49:30.727079Z",
     "start_time": "2020-01-25T12:49:16.298605Z"
    }
   },
   "outputs": [],
   "source": [
    "def value_counts(df):\n",
    "    return df.fare_amount.value_counts()\n",
    "\n",
    "key = 'value counts'\n",
    "f  = value_counts\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-25T12:51:30.334Z"
    }
   },
   "outputs": [],
   "source": [
    "def groupby_statistics(df):\n",
    "    return df.groupby(by='passenger_count').agg({'fare_amount': ['mean', 'std'], \n",
    "                                               'tip_amount': ['mean', 'std']\n",
    "                                              })\n",
    "\n",
    "key = 'groupby statistics'\n",
    "f = groupby_statistics\n",
    "benchmark(f, df=data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = groupby_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-25T13:12:11.561Z"
    }
   },
   "outputs": [],
   "source": [
    "def join(df, other):\n",
    "    return df.join(other=other, on = 'passenger_count', rsuffix = '_right')\n",
    "\n",
    "key = 'join'\n",
    "f = join\n",
    "benchmark(f, data, name=key, repetitions=repetitions, other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_count(df, other):\n",
    "    return len(df.join(other=other, on = 'passenger_count', rsuffix = '_right'))\n",
    "\n",
    "key = 'join count'\n",
    "f = join_count\n",
    "benchmark(f, data, name=key, repetitions=repetitions, other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is not build to run on filter data like you would normally, so we will apply the same strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (df.pickup_longitude > long_min)  & (df.pickup_longitude < long_max) & \\\n",
    "                  (df.pickup_latitude > lat_min)    & (df.pickup_latitude < lat_max) & \\\n",
    "                  (df.dropoff_longitude > long_min) & (df.dropoff_longitude < long_max) & \\\n",
    "                  (df.dropoff_latitude > lat_min)   & (df.dropoff_latitude < lat_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "\n",
    "key = 'filter data'\n",
    "f = filter_data\n",
    "benchmark(f, data, name=key, repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-23T13:55:12.933Z"
    }
   },
   "outputs": [],
   "source": [
    "filterd = filter_data(data)\n",
    "\n",
    "del data\n",
    "print(f\"cleaned {gc.collect()} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(filter_data, filterd, name='filterd count', repetitions=repetitions)\n",
    "benchmark(mean, filterd, name='filterd mean', repetitions=repetitions)\n",
    "benchmark(standard_deviation, filterd, name='filtered standard deviation', repetitions=repetitions)\n",
    "benchmark(mean_of_sum, filterd, name ='filtered sum columns mean', repetitions=repetitions)\n",
    "benchmarks['filtered sum columns'] =  benchmarks['filtered sum columns mean'] - benchmarks['filterd mean']\n",
    "benchmark(mean_of_product, filterd, name ='filterd product columns mean', repetitions=repetitions)\n",
    "benchmarks['filterd product columns'] = benchmarks['filterd product columns mean'] - benchmarks['filterd mean']\n",
    "benchmark(mean_of_complicated_arithmetic_operation, filterd, name='filterd arithmetic operation mean', repetitions=repetitions)\n",
    "benchmarks['filterd arithmetic operation'] =  benchmarks['filterd arithmetic operation mean'] - benchmarks['filterd mean']\n",
    "benchmark(value_counts, filterd, name ='filtered value counts', repetitions=repetitions)\n",
    "benchmark(groupby_statistics, filterd, name='filtered groupby statistics', repetitions=repetitions)\n",
    "other = groupby_statistics(data)\n",
    "benchmarks['filtered join'] = -1\n",
    "benchmarks['filtered join count'] = benchmark(join_count, filterd, repetitions=repetitions, other=other)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
