{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pip\n",
    "!conda update -y --all\n",
    "!pip install --upgrade tensorflow==2.0.0-beta1\n",
    "!pip install --upgrade turicreate\n",
    "!aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_1m.sframe ../datasets/taxi_1m.sframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from src.benchmarks_utils import benchmark, get_results\n",
    "from src.turicreate_utils import *\n",
    "\n",
    "name = 'turicreate'\n",
    "data_path = '../datasets/taxi_1m.sframe'\n",
    "results_path = f\"../results/{name}_1m.csv\"\n",
    "repetitions = 1\n",
    "benchmarks = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1000000 with 19 columns\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = read_file(data_path=data_path)\n",
    "data['pickup_hour'] = data['pickup_datetime'].str_to_datetime().apply(lambda x: x.hour)\n",
    "print(f\"size: {data.shape[0]} with {data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks['read_file']= benchmark(read_file, df=data, data_path=data_path, repetitions=repetitions)\n",
    "benchmarks['mean']= benchmark(mean, data, repetitions=repetitions)\n",
    "benchmarks['standard deviation']= benchmark(standard_deviation, data, repetitions=repetitions)\n",
    "benchmarks['sum columns']= benchmark(sum_columns, data, repetitions=repetitions)\n",
    "benchmarks['product columns']= benchmark(product_columns, data, repetitions=repetitions)\n",
    "benchmarks['arithmetic operation']= benchmark(complicated_arithmetic_operation, data, repetitions=repetitions)\n",
    "benchmarks['value counts']= benchmark(value_counts, data, repetitions=repetitions)\n",
    "benchmarks['groupby statistics']= benchmark(groupby_statistics, data, repetitions=repetitions)\n",
    "benchmarks['filter']= benchmark(filter_data, data, repetitions=repetitions)\n",
    "print(f\"cleaned {gc.collect()} mb\")\n",
    "benchmarks['join'] = benchmark(join, data, repetitions=repetitions, other=groupby_statistics(data))\n",
    "gc.collect()\n",
    "\n",
    "# Sketch\n",
    "benchmarks['sketch mean'] = benchmark(skeatch_mean, data, repetitions=repetitions)\n",
    "gc.collect()\n",
    "benchmarks['sketch standard deviation'] = benchmark(skeatch_standatd_deviation, data, repetitions=repetitions)\n",
    "gc.collect()\n",
    "benchmarks['skeatch frequent items'] = benchmark(skeatch_frequent_items, data, repetitions=repetitions)\n",
    "print(f\"Done benchmarks on all data\")\n",
    "\n",
    "# filtered\n",
    "filterd = filter_data(data)\n",
    "del data\n",
    "\n",
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")\n",
    "benchmarks['filtered mean'] = benchmark(mean, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered standard deviation'] = benchmark(standard_deviation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered sum columns'] = benchmark(sum_columns , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered product_columns'] = benchmark(product_columns , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered complicated arithmetic operation'] = benchmark(complicated_arithmetic_operation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered value counts'] = benchmark(value_counts, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered groupby statistics'] = benchmark(groupby_statistics, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered join'] = benchmark(join, filterd, repetitions=repetitions, other=groupby_statistics(filterd))\n",
    "\n",
    "# Sketch\n",
    "benchmarks['sketch mean'] = benchmark(skeatch_mean, filterd, repetitions=repetitions)\n",
    "gc.collect()\n",
    "benchmarks['sketch standard deviation'] = benchmark(skeatch_standatd_deviation, filterd, repetitions=repetitions)\n",
    "gc.collect()\n",
    "benchmarks['skeatch frequent items'] = benchmark(skeatch_frequent_items, filterd, repetitions=repetitions)\n",
    "print(f\"Done benchmarks on filterd data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(benchmarks, name)\n",
    "results.to_csv(results_path)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp  ../results/turicreate_1m.csv s3://vaex-sagemaker-demo/benchmarks/turicreate_1m_results.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
