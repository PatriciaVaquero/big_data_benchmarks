{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages\n",
    "Use the condat_python3 kernel, not the pyspark one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:05:50.420429Z",
     "start_time": "2020-01-27T11:04:03.465141Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_parquet datasets/taxi_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     26,
     31,
     36
    ]
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "instance_type = 'c5d2xlarge' # change this\n",
    "results_bucket = f\"s3://vaex-sagemaker-demo/benchmarks\" # change this\n",
    "\n",
    "name = 'spark'\n",
    "data_path = 'datasets/taxi_parquet'\n",
    "output_file = f'{name}_{instance_type}_results.csv'\n",
    "results_path = f\"results/{output_file}\"\n",
    "results_bucket = f\"{results_bucket}/{output_file}\" \n",
    "benchmarks = {}\n",
    "single_repetition = 1\n",
    "statistic_repetition = 5\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results\n",
    "\n",
    "def persist():\n",
    "    gc.collect()\n",
    "    get_results(benchmarks, name).to_csv(results_path)\n",
    "    os.system(f\"aws s3 cp {results_path} {results_bucket}\")\n",
    "    \n",
    "def benchmark(f, df, name, repetitions=1, **kwargs):\n",
    "    times = []\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        times.append(time.time()-start_time)\n",
    "    benchmarks[name] = np.mean(times)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks[name]}\")\n",
    "    return benchmarks[name]\n",
    "\n",
    "\n",
    "!mkdir -p results\n",
    "!mkdir -p datasets\n",
    "print(f\"test for {single_repetition} repetitions for join and groupby and {statistic_repetition} repetitions for statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:32:01.461299Z",
     "start_time": "2020-01-27T11:32:00.850915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1173057928 with 18 columns\n"
     ]
    }
   ],
   "source": [
    "from pyspark import sql, SparkConf, SparkContext\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "conf = SparkConf().setAppName('Benchmarks')\n",
    "\n",
    "# make sure you have enough memory for this\n",
    "conf.setExecutorEnv('spark.executor.memory', '2g') \n",
    "conf.setExecutorEnv('spark.driver.memory', '12g')\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = sql.SQLContext(sc)\n",
    "data = sqlContext.read.parquet(data_path)\n",
    "print(f\"size: {data.count()} with {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:32:02.418392Z",
     "start_time": "2020-01-27T11:32:01.463555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_file took: 0.07748112678527833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07748112678527833"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read/ open\n",
    "def open_file(df=None):\n",
    "    return sqlContext.read.parquet(data_path)\n",
    "\n",
    "benchmark(open_file, df=data, name='read_file', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:32:04.748414Z",
     "start_time": "2020-01-27T11:32:02.420107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count took: 0.3561862468719482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3561862468719482"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count(df=None):\n",
    "    return df.count()\n",
    "\n",
    "benchmark(count, df=data, name='count', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:32:17.650162Z",
     "start_time": "2020-01-27T11:32:04.750781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean took: 2.4659940719604494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4659940719604494"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean(df):\n",
    "    return df.select(f.mean('fare_amount')).collect()\n",
    "\n",
    "benchmark(mean, df=data, name='mean', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:32:36.952526Z",
     "start_time": "2020-01-27T11:32:17.651986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard took: 3.7465686321258547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7465686321258547"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_deviation(df):\n",
    "    return df.select(f.stddev('fare_amount')).collect()\n",
    "\n",
    "benchmark(standard_deviation, df=data, name='standard deviation', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other techonlogies, vaex can return columns, or subset of values to explore lazely, \n",
    "but becouse many of the other tecnologies crashed at this point, we return a scalar instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:32:55.849280Z",
     "start_time": "2020-01-27T11:32:36.954276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum columns mean took: 3.65928635597229\n"
     ]
    }
   ],
   "source": [
    "def mean_of_sum(df):\n",
    "    return df.select(f.mean(df['fare_amount'] + df['trip_distance'])).collect()\n",
    "\n",
    "benchmark(mean_of_sum, df=data, name='sum columns mean', repetitions=statistic_repetition)\n",
    "benchmarks['sum columns'] =  np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:33:15.278213Z",
     "start_time": "2020-01-27T11:32:55.851272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product columns mean took: 3.7690373420715333\n"
     ]
    }
   ],
   "source": [
    "def mean_of_product(df):\n",
    "    return df.select(f.mean(df['fare_amount'] * df['trip_distance'])).collect()\n",
    "\n",
    "benchmark(mean_of_product, df=data, name='product columns mean', repetitions=statistic_repetition)\n",
    "benchmarks['product columns'] =  np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:34:52.857494Z",
     "start_time": "2020-01-27T11:33:15.280296Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arithmetic operation mean took: 96.96435236930847\n"
     ]
    }
   ],
   "source": [
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df['pickup_longitude']\n",
    "    phi_1 = df['pickup_latitude']\n",
    "    theta_2 = df['dropoff_longitude']\n",
    "    phi_2 = df['dropoff_latitude']\n",
    "    temp = (f.cos(theta_1)*np.pi/180) * (f.cos(theta_2)*np.pi/180) * (f.sin(phi_2-phi_1)/2*np.pi/180)**2\n",
    "    expression = 2 * f.atan2(f.sqrt(temp), f.sqrt(1-temp))\n",
    "    return df.select(f.mean(expression)).collect()\n",
    "\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=data, name='arithmetic operation mean', repetitions=single_repetition)\n",
    "benchmarks['arithmetic operation'] =  np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:35:52.118966Z",
     "start_time": "2020-01-27T11:34:52.859386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value counts took: 11.73745174407959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.73745174407959"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value_counts(df):\n",
    "    return df.select('fare_amount').distinct().collect()\n",
    "\n",
    "benchmark(value_counts, df=data, name='value counts', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:36:24.833614Z",
     "start_time": "2020-01-27T11:35:52.120749Z"
    },
    "code_folding": [
     10
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby statistics took: 32.12943077087402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.12943077087402"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def groupby_statistics(df):\n",
    "    ret = df.groupby('passenger_count').agg(\n",
    "        f.mean('fare_amount'),\n",
    "        f.stddev('fare_amount'),\n",
    "        f.mean('tip_amount'),\n",
    "        f.stddev('tip_amount')\n",
    "    )\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "\n",
    "benchmark(groupby_statistics, df=data, name='groupby statistics', repetitions=single_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:36:54.413563Z",
     "start_time": "2020-01-27T11:36:24.835399Z"
    }
   },
   "outputs": [],
   "source": [
    "other = groupby_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(df, other):\n",
    "    ret = df.join(other, on = 'passenger_count')\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "    \n",
    "benchmark(join, data, name='join', repetitions=single_repetition, other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_count(df, other):\n",
    "    return df.join(other, on = 'passenger_count').count()\n",
    "\n",
    "benchmark(join_count, data, name='join count', repetitions=single_repetition, other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is not build to run on filter data like you would normally, so we will apply the same strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:54:23.828214Z",
     "start_time": "2020-01-27T11:54:23.774494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare filtered data and deleted 0 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:54:25.060970Z",
     "start_time": "2020-01-27T11:54:23.830425Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter took: 0.12175817489624023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12175817489624023"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_data(df):\n",
    "    expr_filter = (df.pickup_longitude > long_min)  & (df.pickup_longitude < long_max) & \\\n",
    "              (df.pickup_latitude > lat_min)    & (df.pickup_latitude < lat_max) & \\\n",
    "              (df.dropoff_longitude > long_min) & (df.dropoff_longitude < long_max) & \\\n",
    "              (df.dropoff_latitude > lat_min)   & (df.dropoff_latitude < lat_max)\n",
    "    ret = df[expr_filter]\n",
    "    ret.take(3) # evaluate the filter\n",
    "    return ret\n",
    "benchmark(filter_data, data, name='filter data', repetitions=statistic_repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:54:25.199848Z",
     "start_time": "2020-01-27T11:54:25.063034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned 194 mb\n"
     ]
    }
   ],
   "source": [
    "filterd = filter_data(data)\n",
    "\n",
    "del data\n",
    "print(f\"cleaned {gc.collect()} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-27T11:49:06.041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filterd count took: 0.08333163261413574\n",
      "filterd mean took: 17.987318897247313\n",
      "filtered standard deviation took: 17.573638582229613\n",
      "filtered sum columns mean took: 21.039139175415038\n",
      "filterd product columns mean took: 20.938899803161622\n"
     ]
    }
   ],
   "source": [
    "benchmark(filter_data, filterd, name='filterd count', repetitions=statistic_repetition)\n",
    "benchmark(mean, filterd, name='filterd mean', repetitions=statistic_repetition)\n",
    "benchmark(standard_deviation, filterd, name='filtered standard deviation', repetitions=statistic_repetition)\n",
    "benchmark(mean_of_sum, filterd, name ='filtered sum columns mean', repetitions=statistic_repetition)\n",
    "benchmarks['filtered sum columns'] =  np.nan\n",
    "benchmark(mean_of_product, filterd, name ='filterd product columns mean', repetitions=statistic_repetition)\n",
    "benchmarks['filterd product columns'] = np.nan\n",
    "benchmark(mean_of_complicated_arithmetic_operation, filterd, name='filterd arithmetic operation mean', repetitions=statistic_repetition)\n",
    "benchmarks['filterd arithmetic operation'] =  np.nan\n",
    "benchmark(value_counts, filterd, name ='filtered value counts', repetitions=statistic_repetition)\n",
    "benchmark(groupby_statistics, filterd, name='filtered groupby statistics', repetitions=single_repetition)\n",
    "other = groupby_statistics(filterd)\n",
    "benchmark(join, filterd, name='filtered join', repetitions=single_repetition, other=other)\n",
    "benchmark(join_count, filterd, name='filtered join count', repetitions=single_repetition, other=other)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-27T11:49:06.209Z"
    }
   },
   "outputs": [],
   "source": [
    "print('spark')\n",
    "benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
