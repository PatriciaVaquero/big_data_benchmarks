{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages\n",
    "Use the condat_python3 kernel, not the pyspark one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:14:38.955262Z",
     "start_time": "2020-03-09T14:12:44.987941Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_parquet datasets/taxi_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:16.927567Z",
     "start_time": "2020-05-13T11:24:16.684519Z"
    },
    "code_folding": [
     26,
     31,
     36
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We test every benchmark twice and save both results\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "instance_type = 'c5d2xlarge' # change this\n",
    "results_bucket = f\"s3://vaex-sagemaker-demo/benchmarks\" # change this\n",
    "\n",
    "name = 'spark'\n",
    "data_path = 'datasets/taxi_parquet'\n",
    "output_file = f'{name}_{instance_type}.csv'\n",
    "results_path = f\"results/{output_file}\"\n",
    "results_bucket = f\"{results_bucket}/{output_file}\" \n",
    "benchmarks = {\n",
    "    'run':[],\n",
    "    'duration': [],\n",
    "    'task': []   \n",
    "}\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "\n",
    "\n",
    "def get_results(benchmarks=benchmarks):\n",
    "    return pd.DataFrame.from_dict(benchmarks, orient='index').T\n",
    "\n",
    "def persist():\n",
    "    gc.collect()\n",
    "    get_results(benchmarks).to_csv(results_path)\n",
    "    os.system(f\"aws s3 cp {results_path} {results_bucket}\")\n",
    "    \n",
    "def benchmark(f, df, name, **kwargs):    \n",
    "    for i in range(2):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        benchmarks['duration'].append(time.time()-start_time)\n",
    "        benchmarks['task'].append(name)\n",
    "        benchmarks['run'].append(i+1)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]}\")\n",
    "    return benchmarks['duration'][-1]\n",
    "          \n",
    "def add_nan(name):\n",
    "    for i in range(2):\n",
    "        benchmarks['duration'].append(np.nan)\n",
    "        benchmarks['task'].append(name)\n",
    "        benchmarks['run'].append(i+1)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]}\")\n",
    "    return benchmarks['duration'][-1]\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "!mkdir -p results\n",
    "!mkdir -p datasets\n",
    "print(f\"We test every benchmark twice and save both results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:17.117917Z",
     "start_time": "2020-05-13T11:24:17.102154Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import sql, SparkConf, SparkContext\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "conf = SparkConf().setAppName('Benchmarks')\n",
    "\n",
    "# make sure you have enough memory for this\n",
    "conf.setExecutorEnv('spark.executor.memory', '2g') \n",
    "conf.setExecutorEnv('spark.driver.memory', '12g')\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = sql.SQLContext(sc)\n",
    "data = sqlContext.read.parquet(data_path)\n",
    "print(f\"size: {data.count()} with {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:23.509480Z",
     "start_time": "2020-05-13T11:24:22.842850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_file took: 0.05755162239074707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05755162239074707"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read/ open\n",
    "def open_file(df=None):\n",
    "    return sqlContext.read.parquet(data_path)\n",
    "\n",
    "benchmark(open_file, df=data, name='read_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:24.668737Z",
     "start_time": "2020-05-13T11:24:23.511183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count took: 0.31055116653442383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31055116653442383"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count(df=None):\n",
    "    return df.count()\n",
    "\n",
    "benchmark(count, df=data, name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:29.865171Z",
     "start_time": "2020-05-13T11:24:24.670364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean took: 2.3144118785858154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3144118785858154"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean(df):\n",
    "    return df.select(f.mean('fare_amount')).collect()\n",
    "\n",
    "benchmark(mean, df=data, name='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:37.456309Z",
     "start_time": "2020-05-13T11:24:29.867177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation took: 3.491633176803589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.491633176803589"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_deviation(df):\n",
    "    return df.select(f.stddev('fare_amount')).collect()\n",
    "\n",
    "benchmark(standard_deviation, df=data, name='standard deviation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other techonlogies, vaex can return columns, or subset of values to explore lazely, \n",
    "but becouse many of the other tecnologies crashed at this point, we return a scalar instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:45.815381Z",
     "start_time": "2020-05-13T11:24:37.459022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum columns mean took: 3.6596174240112305\n",
      "sum columns took: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_sum(df):\n",
    "    return df.select(f.mean(df['fare_amount'] + df['trip_distance'])).collect()\n",
    "\n",
    "benchmark(mean_of_sum, df=data, name='sum columns mean')\n",
    "add_nan('sum columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:24:54.378735Z",
     "start_time": "2020-05-13T11:24:45.816858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product columns mean took: 3.7124032974243164\n",
      "product columns took: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_product(df):\n",
    "    return df.select(f.mean(df['fare_amount'] * df['trip_distance'])).collect()\n",
    "\n",
    "benchmark(mean_of_product, df=data, name='product columns mean')\n",
    "add_nan('product columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:30:35.040221Z",
     "start_time": "2020-05-13T11:24:54.380265Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arithmetic operation mean took: 92.70115447044373\n",
      "arithmetic operation took: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df['pickup_longitude']\n",
    "    phi_1 = df['pickup_latitude']\n",
    "    theta_2 = df['dropoff_longitude']\n",
    "    phi_2 = df['dropoff_latitude']\n",
    "    temp = (f.cos(theta_1)*np.pi/180) * (f.cos(theta_2)*np.pi/180) * (f.sin(phi_2-phi_1)/2*np.pi/180)**2\n",
    "    expression = 2 * f.atan2(f.sqrt(temp), f.sqrt(1-temp))\n",
    "    return df.select(f.mean(expression)).collect()\n",
    "\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=data, name='arithmetic operation mean')\n",
    "add_nan('arithmetic operation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:31:05.792696Z",
     "start_time": "2020-05-13T11:30:35.041800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value counts took: 8.365249872207642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.365249872207642"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value_counts(df):\n",
    "    return df.select('passenger_count').distinct().collect()\n",
    "\n",
    "benchmark(value_counts, df=data, name='value counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:32:36.758307Z",
     "start_time": "2020-05-13T11:31:05.794123Z"
    },
    "code_folding": [
     10
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby statistics took: 31.955618381500244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.955618381500244"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def groupby_statistics(df):\n",
    "    ret = df.groupby('passenger_count').agg(\n",
    "        f.mean('fare_amount'),\n",
    "        f.stddev('fare_amount'),\n",
    "        f.mean('tip_amount'),\n",
    "        f.stddev('tip_amount')\n",
    "    )\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "\n",
    "benchmark(groupby_statistics, df=data, name='groupby statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:33:08.348874Z",
     "start_time": "2020-05-13T11:32:36.759824Z"
    }
   },
   "outputs": [],
   "source": [
    "other = groupby_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:33:08.892928Z",
     "start_time": "2020-05-13T11:33:08.350822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join took: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join(df, other):\n",
    "    ret = df.join(other, on = 'passenger_count')\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "    \n",
    "# benchmark(join, data, name='join', other=other)\n",
    "add_nan('join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:43:19.659245Z",
     "start_time": "2020-05-13T11:33:08.894415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join count took: 296.01428627967834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "296.01428627967834"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_count(df, other):\n",
    "    return df.join(other, on = 'passenger_count').count()\n",
    "\n",
    "benchmark(join_count, data, name='join count', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is not build to run on filter data like you would normally, so we will apply the same strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:43:19.755513Z",
     "start_time": "2020-05-13T11:43:19.660756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare filtered data and deleted 0 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:43:23.719020Z",
     "start_time": "2020-05-13T11:43:19.756824Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter data took: 0.0840616226196289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0840616226196289"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_data(df):\n",
    "    expr_filter = (df.pickup_longitude > long_min)  & (df.pickup_longitude < long_max) & \\\n",
    "              (df.pickup_latitude > lat_min)    & (df.pickup_latitude < lat_max) & \\\n",
    "              (df.dropoff_longitude > long_min) & (df.dropoff_longitude < long_max) & \\\n",
    "              (df.dropoff_latitude > lat_min)   & (df.dropoff_latitude < lat_max)\n",
    "    ret = df[expr_filter]\n",
    "    ret.take(3) # evaluate the filter\n",
    "    return ret\n",
    "benchmark(filter_data, data, name='filter data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:43:23.992154Z",
     "start_time": "2020-05-13T11:43:23.720538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned 194 mb\n"
     ]
    }
   ],
   "source": [
    "filtered = filter_data(data)\n",
    "\n",
    "del data\n",
    "print(f\"cleaned {gc.collect()} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:51:50.466938Z",
     "start_time": "2020-05-13T11:43:23.994080Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark(filter_data, filtered, name='filtered count')\n",
    "benchmark(mean, filtered, name='filtered mean')\n",
    "benchmark(standard_deviation, filtered, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, filtered, name ='filtered sum columns mean')\n",
    "add_nan('filtered sum columns')\n",
    "benchmark(mean_of_product, filtered, name ='filtered product columns mean')\n",
    "add_nan('filtered product columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, filtered, name='filtered arithmetic operation mean')\n",
    "add_nan('filtered arithmetic operation')\n",
    "benchmark(value_counts, filtered, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, filtered, name='filtered groupby statistics')\n",
    "other = groupby_statistics(filtered)\n",
    "add_nan('filtered join')\n",
    "benchmark(join_count, filtered, name='filtered join count', other=other)\n",
    "print(name)\n",
    "get_results(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T12:49:15.894766Z",
     "start_time": "2020-05-13T12:49:15.878747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done spark\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>duration</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0678499</td>\n",
       "      <td>read_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0575516</td>\n",
       "      <td>read_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.283383</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.310551</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.32047</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2.31441</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3.5441</td>\n",
       "      <td>standard deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3.49163</td>\n",
       "      <td>standard deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3.61367</td>\n",
       "      <td>sum columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3.65962</td>\n",
       "      <td>sum columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sum columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sum columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>3.69822</td>\n",
       "      <td>product columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3.7124</td>\n",
       "      <td>product columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>product columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>product columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>246.638</td>\n",
       "      <td>arithmetic operation mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>92.7012</td>\n",
       "      <td>arithmetic operation mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arithmetic operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arithmetic operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>21.8349</td>\n",
       "      <td>value counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>8.36525</td>\n",
       "      <td>value counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>58.4053</td>\n",
       "      <td>groupby statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>31.9556</td>\n",
       "      <td>groupby statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>314.145</td>\n",
       "      <td>join count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>296.014</td>\n",
       "      <td>join count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3.29265</td>\n",
       "      <td>filter data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0840616</td>\n",
       "      <td>filter data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.114831</td>\n",
       "      <td>filterd count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0857303</td>\n",
       "      <td>filterd count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>16.2448</td>\n",
       "      <td>filterd mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>14.736</td>\n",
       "      <td>filterd mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>16.3177</td>\n",
       "      <td>filtered standard deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>16.242</td>\n",
       "      <td>filtered standard deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>19.4521</td>\n",
       "      <td>filtered sum columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>19.1565</td>\n",
       "      <td>filtered sum columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filtered sum columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filtered sum columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>19.1523</td>\n",
       "      <td>filterd product columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>19.0768</td>\n",
       "      <td>filterd product columns mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filterd product columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filterd product columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>90.0942</td>\n",
       "      <td>filterd arithmetic operation mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>89.3027</td>\n",
       "      <td>filterd arithmetic operation mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filterd arithmetic operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filterd arithmetic operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0005</td>\n",
       "      <td>filtered value counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>21.9868</td>\n",
       "      <td>filtered value counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>45.3997</td>\n",
       "      <td>filtered groupby statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>44.8847</td>\n",
       "      <td>filtered groupby statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filtered join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>filtered join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>323.691</td>\n",
       "      <td>filtered join count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>327.254</td>\n",
       "      <td>filtered join count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run   duration                               task\n",
       "0    1  0.0678499                          read_file\n",
       "1    2  0.0575516                          read_file\n",
       "2    1   0.283383                              count\n",
       "3    2   0.310551                              count\n",
       "4    1    2.32047                               mean\n",
       "5    2    2.31441                               mean\n",
       "6    1     3.5441                 standard deviation\n",
       "7    2    3.49163                 standard deviation\n",
       "8    1    3.61367                   sum columns mean\n",
       "9    2    3.65962                   sum columns mean\n",
       "10   1        NaN                        sum columns\n",
       "11   2        NaN                        sum columns\n",
       "12   1    3.69822               product columns mean\n",
       "13   2     3.7124               product columns mean\n",
       "14   1        NaN                    product columns\n",
       "15   2        NaN                    product columns\n",
       "16   1    246.638          arithmetic operation mean\n",
       "17   2    92.7012          arithmetic operation mean\n",
       "18   1        NaN               arithmetic operation\n",
       "19   2        NaN               arithmetic operation\n",
       "20   1    21.8349                       value counts\n",
       "21   2    8.36525                       value counts\n",
       "22   1    58.4053                 groupby statistics\n",
       "23   2    31.9556                 groupby statistics\n",
       "24   1        NaN                               join\n",
       "25   2        NaN                               join\n",
       "26   1    314.145                         join count\n",
       "27   2    296.014                         join count\n",
       "28   1    3.29265                        filter data\n",
       "29   2  0.0840616                        filter data\n",
       "30   1   0.114831                      filterd count\n",
       "31   2  0.0857303                      filterd count\n",
       "32   1    16.2448                       filterd mean\n",
       "33   2     14.736                       filterd mean\n",
       "34   1    16.3177        filtered standard deviation\n",
       "35   2     16.242        filtered standard deviation\n",
       "36   1    19.4521          filtered sum columns mean\n",
       "37   2    19.1565          filtered sum columns mean\n",
       "38   1        NaN               filtered sum columns\n",
       "39   2        NaN               filtered sum columns\n",
       "40   1    19.1523       filterd product columns mean\n",
       "41   2    19.0768       filterd product columns mean\n",
       "42   1        NaN            filterd product columns\n",
       "43   2        NaN            filterd product columns\n",
       "44   1    90.0942  filterd arithmetic operation mean\n",
       "45   2    89.3027  filterd arithmetic operation mean\n",
       "46   1        NaN       filterd arithmetic operation\n",
       "47   2        NaN       filterd arithmetic operation\n",
       "48   1    22.0005              filtered value counts\n",
       "49   2    21.9868              filtered value counts\n",
       "50   1    45.3997        filtered groupby statistics\n",
       "51   2    44.8847        filtered groupby statistics\n",
       "52   1        NaN                      filtered join\n",
       "53   2        NaN                      filtered join\n",
       "54   1    323.691                filtered join count\n",
       "55   2    327.254                filtered join count"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Done spark')\n",
    "get_results(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
