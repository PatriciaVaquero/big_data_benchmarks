{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:03:46.683599Z",
     "start_time": "2020-01-27T11:03:44.894169Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install -U pip modin[all]\n",
    "# aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_parquet datasets/taxi_parquet/data_0.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can only read a single parquet file - keep only for code references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:53:45.885720Z",
     "start_time": "2020-02-18T13:53:45.308674Z"
    },
    "code_folding": [
     33,
     38,
     43
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for 1 repetitions for join and groupby and 5 repetitions for statistics\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import os\n",
    "\n",
    "\n",
    "instance_type = 'c5d2xlarge' # change this\n",
    "results_bucket = f\"s3://vaex-sagemaker-demo/benchmarks\" # change this\n",
    "\n",
    "os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "name = 'modin-ray'\n",
    "data_path = 'datasets/taxi_parquet/data_0.parquet'\n",
    "output_file = f'{name}_{instance_type}_1m.csv'\n",
    "results_path = f\"results/{output_file}\"\n",
    "results_bucket = f\"{results_bucket}/{output_file}\" \n",
    "benchmarks = {\n",
    "    'run':[],\n",
    "    'duration': [],\n",
    "    'task': []   \n",
    "}\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "\n",
    "\n",
    "def get_results(benchmarks=benchmarks):\n",
    "    return pd.DataFrame.from_dict(benchmarks, orient='index').T\n",
    "\n",
    "def persist():\n",
    "    gc.collect()\n",
    "    get_results(benchmarks).to_csv(results_path)\n",
    "    os.system(f\"aws s3 cp {results_path} {results_bucket}\")\n",
    "    \n",
    "def benchmark(f, df, name, **kwargs):    \n",
    "    for i in range(2):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        benchmarks['duration'].append(time.time()-start_time)\n",
    "        benchmarks['task'].append(name)\n",
    "        benchmarks['run'].append(i+1)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]}\")\n",
    "    return benchmarks['duration'][-1]\n",
    "          \n",
    "def add_nan(name):\n",
    "    for i in range(2):\n",
    "        benchmarks['duration'].append(np.nan)\n",
    "        benchmarks['task'].append(name)\n",
    "        benchmarks['run'].append(i+1)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]}\")\n",
    "    return benchmarks['duration'][-1]\n",
    "\n",
    "        \n",
    "\n",
    "!mkdir -p results\n",
    "!mkdir -p datasets\n",
    "print(f\"We test every benchmark twice and save both results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:53:51.632779Z",
     "start_time": "2020-02-18T13:53:48.606300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The Dask Engine for Modin is experimental.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1000000 with 18 columns\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = pd.read_parquet(data_path, engine='pyarrow')\n",
    "print(f\"size: {len(data)} with {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:14.353180Z",
     "start_time": "2020-02-18T13:39:05.948495Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_file took: 1.5481024742126466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5481024742126466"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return pd.read_parquet(data_path, engine='pyarrow')\n",
    "\n",
    "benchmark(read_file_parquet, df=data, name='read_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:15.517446Z",
     "start_time": "2020-02-18T13:39:14.355144Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count took: 1.2254714965820312e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2254714965820312e-05"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count(df=None):\n",
    "    return len(df)\n",
    "\n",
    "benchmark(count, df=data, name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:16.597380Z",
     "start_time": "2020-02-18T13:39:15.519015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean took: 0.05955638885498047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05955638885498047"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean(df):\n",
    "    return df.fare_amount.mean()\n",
    "\n",
    "benchmark(mean, df=data, name='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:17.374782Z",
     "start_time": "2020-02-18T13:39:16.599136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation took: 0.04032907485961914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04032907485961914"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std()\n",
    "\n",
    "benchmark(standard_deviation, df=data, name='standard deviation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the time when using two columns, we can't return the response since it will get into memroy and break, so we run a mean calculation on it, and then remove the time it took to run the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:18.632582Z",
     "start_time": "2020-02-18T13:39:17.376503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum columns mean took: 0.13871545791625978\n"
     ]
    }
   ],
   "source": [
    "def mean_of_sum(df):\n",
    "    return (df.fare_amount + df.trip_distance).mean()\n",
    "\n",
    "benchmark(mean_of_sum, df=data, name='sum columns mean')\n",
    "add_nan('sum columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:19.973659Z",
     "start_time": "2020-02-18T13:39:18.634845Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product columns mean took: 0.14782986640930176\n"
     ]
    }
   ],
   "source": [
    "def mean_of_product(df):\n",
    "    return (df.fare_amount * df.trip_distance).mean()\n",
    "\n",
    "benchmark(mean_of_product, df=data, name='product columns mean')\n",
    "add_nan('product columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:22.053237Z",
     "start_time": "2020-02-18T13:39:19.975743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `Series.__array_wrap__` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n",
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arithmetic operation mean took: 1.4310154914855957\n"
     ]
    }
   ],
   "source": [
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.pickup_longitude\n",
    "    phi_1 = df.pickup_latitude\n",
    "    theta_2 = df.dropoff_longitude\n",
    "    phi_2 = df.dropoff_latitude\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(np.subtract(1, temp))),2) \n",
    "    return ret.mean()\n",
    "\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=data, name='arithmetic operation mean')\n",
    "add_nan('arithmetic operation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:23.309743Z",
     "start_time": "2020-02-18T13:39:22.055132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `Series.value_counts` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n",
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value counts took: 0.13008618354797363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13008618354797363"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value_counts(df):\n",
    "    return df.fare_amount.value_counts()\n",
    "\n",
    "benchmark(value_counts, df=data, name='value counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:25.078681Z",
     "start_time": "2020-02-18T13:39:23.311854Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `DataFrame.groupby_on_multiple_columns` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby statistics took: 1.2036387920379639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2036387920379639"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def groupby_statistics(df):\n",
    "    return df.groupby(by='passenger_count').agg({'fare_amount': ['mean', 'std'], \n",
    "                                               'tip_amount': ['mean', 'std']\n",
    "                                              })\n",
    "\n",
    "benchmark(groupby_statistics, df=data, name='groupby statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:27.239491Z",
     "start_time": "2020-02-18T13:39:26.118328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `DataFrame.groupby_on_multiple_columns` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "other = groupby_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:28.192369Z",
     "start_time": "2020-02-18T13:39:27.241002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "UserWarning: `from_dict` defaulting to pandas implementation.\n",
      "UserWarning: `DataFrame.to_csv` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join count took: 0.39369869232177734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39369869232177734"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_count(df, other):\n",
    "    return len(pd.merge(df, other, left_index=True, right_index=True))\n",
    "\n",
    "benchmark(join_count, data, name='join count', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(df, other):\n",
    "    return pd.merge(df, other, left_index=True, right_index=True)\n",
    "\n",
    "benchmark(join_count, data, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is not build to run on filter data like you would normally, so we will apply the same strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:39:28.251333Z",
     "start_time": "2020-02-18T13:39:28.194054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare filtered data and deleted 22 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T13:39:09.243Z"
    }
   },
   "outputs": [],
   "source": [
    "expr_filter = (data.pickup_longitude > long_min)  & (data.pickup_longitude < long_max) & \\\n",
    "                  (data.pickup_latitude > lat_min)    & (data.pickup_latitude < lat_max) & \\\n",
    "                  (data.dropoff_longitude > long_min) & (data.dropoff_longitude < long_max) & \\\n",
    "                  (data.dropoff_latitude > lat_min)   & (data.dropoff_latitude < lat_max)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "\n",
    "benchmark(filter_data, data, name='filter data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T13:39:09.664Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered = filter_data(data)\n",
    "\n",
    "del data\n",
    "print(f\"cleaned {gc.collect()} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T13:39:09.935Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark(mean, filtered, name='filtered mean')\n",
    "benchmark(standard_deviation, filtered, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, filtered, name ='filtered sum columns mean')\n",
    "add_nan('filtered sum columns')\n",
    "benchmark(mean_of_product, filtered, name ='filtered product columns mean')\n",
    "add_nan('filtered product columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, filtered, name='filtered arithmetic operation mean')\n",
    "add_nan('filtered arithmetic operation')\n",
    "benchmark(value_counts, filtered, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, filtered, name='filtered groupby statistics')\n",
    "other = groupby_statistics(filtered)\n",
    "add_nan('filtered join')\n",
    "benchmark(join_count, filtered, name='filtered join count', other=other)\n",
    "print(name)\n",
    "get_results(benchmarks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
