{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!aws s3 cp s3://xdss-public-datasets/demos/taxi_1m.csv datasets/taxi_1m.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "benchmarks = {}\n",
    "\n",
    "def benchmark(f, repetitions=1):\n",
    "    times = []\n",
    "    count = 0\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f()\n",
    "        times.append(time.time()-start_time)\n",
    "        count+=1\n",
    "    benchmarks[f.__name__] = np.mean(times)/count\n",
    "    return benchmarks[f.__name__]\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/taxi_1m.csv')\n",
    "\n",
    "df.pickup_datetime = pd.to_datetime(df.pickup_datetime)\n",
    "df['pickup_hour'] = df.pickup_datetime.dt.hour\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "\n",
    "expr_filter = (df.pickup_longitude > long_min)  & (df.pickup_longitude < long_max) & \\\n",
    "              (df.pickup_latitude > lat_min)    & (df.pickup_latitude < lat_max) & \\\n",
    "              (df.dropoff_longitude > long_min) & (df.dropoff_longitude < long_max) & \\\n",
    "              (df.dropoff_latitude > lat_min)   & (df.dropoff_latitude < lat_max)\n",
    "\n",
    "filterd = df[expr_filter]\n",
    "\n",
    "gp = df.groupby(by='pickup_hour').agg({'fare_amount': ['mean', 'std'], \n",
    "                                        'tip_amount': ['mean', 'std']\n",
    "                                        })\n",
    "\n",
    "\n",
    "\n",
    "def read_csv():\n",
    "    return pd.read_csv('datasets/taxi_1m.csv')\n",
    "    \n",
    "def mean():\n",
    "    return df.fare_amount.mean()\n",
    "    \n",
    "def standard_deviation():\n",
    "    return df.fare_amount.std()\n",
    "\n",
    "def sum_columns():\n",
    "    return df.eval('fare_amount + passenger_count') \n",
    "\n",
    "def product_columns():\n",
    "    return df.eval('fare_amount * passenger_count') \n",
    "\n",
    "def complicated_arithmetic_operation():\n",
    "    theta_1 = df.pickup_longitude\n",
    "    phi_1 = df.pickup_latitude\n",
    "    theta_2 = df.dropoff_longitude\n",
    "    phi_2 = df.dropoff_latitude\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    return 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "\n",
    "def value_counts():\n",
    "    return df.passenger_count.value_counts()\n",
    "\n",
    "def groupby_statistics():\n",
    "    return df.groupby(by='pickup_hour').agg({'fare_amount': ['mean', 'std'], \n",
    "                                               'tip_amount': ['mean', 'std']\n",
    "                                              })\n",
    "def join():\n",
    "    df_joined = df.join(other=gp, on = 'pickup_hour', rsuffix = '_right')\n",
    "    \n",
    "\n",
    "def filter_data():\n",
    "    return df[expr_filter]\n",
    "\n",
    "\n",
    "def mean_filtered():\n",
    "    return df.fare_amount.mean()\n",
    "    \n",
    "def standard_deviation_filtered():\n",
    "    return df.fare_amount.std()\n",
    "\n",
    "def sum_columns_filtered():\n",
    "    return df.eval('fare_amount + passenger_count') \n",
    "\n",
    "def product_columns_filtered():\n",
    "    return df.eval('fare_amount * passenger_count') \n",
    "\n",
    "def complicated_arithmetic_operation_filtered():\n",
    "    theta_1 = df.pickup_longitude\n",
    "    phi_1 = df.pickup_latitude\n",
    "    theta_2 = df.dropoff_longitude\n",
    "    phi_2 = df.dropoff_latitude\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    return 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "\n",
    "def value_counts_filtered():\n",
    "    return df.passenger_count.value_counts()\n",
    "\n",
    "def groupby_statistics_filtered():\n",
    "    return df.groupby(by='pickup_hour').agg({'fare_amount': ['mean', 'std'], \n",
    "                                               'tip_amount': ['mean', 'std']\n",
    "                                              })\n",
    "def join_filtered():\n",
    "    return df.join(other=gp, on = 'pickup_hour', rsuffix = '_right')\n",
    "    \n",
    "\n",
    "def filter_data():\n",
    "    return df[expr_filter]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_to_benchmark = [mean, \n",
    "                          standard_deviation, \n",
    "                          sum_columns,\n",
    "                          product_columns,\n",
    "                          complicated_arithmetic_operation,\n",
    "                          value_counts,\n",
    "                          groupby_statistics,\n",
    "                          join,\n",
    "                          filter_data,\n",
    "                          mean_filtered,\n",
    "                          standard_deviation_filtered,\n",
    "                          sum_columns_filtered,\n",
    "                          product_columns_filtered,\n",
    "                          complicated_arithmetic_operation_filtered,\n",
    "                          value_counts_filtered,\n",
    "                          groupby_statistics_filtered,\n",
    "                          join_filtered,\n",
    "                          filter_data\n",
    "                         ]\n",
    "for f in functions_to_benchmark:\n",
    "    benchmark(f, repetitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard_deviation</th>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_columns</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_columns</th>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complicated_arithmetic_operation</th>\n",
       "      <td>0.015879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_counts</th>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groupby_statistics</th>\n",
       "      <td>0.004074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>0.016456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filter_data</th>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_filtered</th>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard_deviation_filtered</th>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_columns_filtered</th>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_columns_filtered</th>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complicated_arithmetic_operation_filtered</th>\n",
       "      <td>0.015485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_counts_filtered</th>\n",
       "      <td>0.000784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groupby_statistics_filtered</th>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join_filtered</th>\n",
       "      <td>0.014632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pandas\n",
       "mean                                       0.000129\n",
       "standard_deviation                         0.000238\n",
       "sum_columns                                0.000722\n",
       "product_columns                            0.000657\n",
       "complicated_arithmetic_operation           0.015879\n",
       "value_counts                               0.000812\n",
       "groupby_statistics                         0.004074\n",
       "join                                       0.016456\n",
       "filter_data                                0.009400\n",
       "mean_filtered                              0.000125\n",
       "standard_deviation_filtered                0.000236\n",
       "sum_columns_filtered                       0.000554\n",
       "product_columns_filtered                   0.000516\n",
       "complicated_arithmetic_operation_filtered  0.015485\n",
       "value_counts_filtered                      0.000784\n",
       "groupby_statistics_filtered                0.004067\n",
       "join_filtered                              0.014632"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_results(benchmarks, 'pandas')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
