{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:06.690430Z",
     "start_time": "2020-01-13T14:20:54.182849Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install jupyter_contrib_nbextensions\n",
    "pip install jupyter_nbextensions_configurator\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "jupyter nbextension enable codefolding/main\n",
    "jupyter nbextension enable scratchpad/main\n",
    "jupyter nbextension enable execute_time/ExecuteTime\n",
    "jupyter nbextension enable autosavetime/main\n",
    "pip install -U pip dask numpy fsspec>=0.3.3 tqdm pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_parquet ../datasets/taxi_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:49:13.855198Z",
     "start_time": "2020-01-25T15:49:13.851215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for 1 repetitions\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from src.config import repetitions\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "instance_type = 'mlm52xlarge'\n",
    "name = 'spark'\n",
    "data_path = '../datasets/taxi_parquet'\n",
    "instance_type = 'mlm52xlarge'\n",
    "results_path = f\"../results/{name}_1b_{instance_type}.csv\"\n",
    "benchmarks = {}\n",
    "print(f\"test for {repetitions} repetitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:49:14.758171Z",
     "start_time": "2020-01-25T15:49:14.753302Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "\n",
    "def get_results(benchmarks, name):\n",
    "    results = pd.DataFrame.from_dict(benchmarks, orient='index')\n",
    "    results.columns = [name]\n",
    "    return results\n",
    "\n",
    "def persist():\n",
    "    get_results(benchmarks, name).to_csv(results_path)\n",
    "    !aws s3 cp  ../results/spark_1b_mlm52xlarge.csv s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv \n",
    "    \n",
    "def benchmark(f, df, name, repetitions=1, **kwargs):\n",
    "    times = []\n",
    "    for i in range(repetitions):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        times.append(time.time()-start_time)\n",
    "    benchmarks[name] = np.mean(times)\n",
    "    persist()\n",
    "    print(f\"{name} took: {benchmarks[name]}\")\n",
    "    return benchmarks[name]\n",
    "\n",
    "\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:53:27.912393Z",
     "start_time": "2020-01-25T15:53:27.899809Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import sql, SparkConf, SparkContext\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "conf = SparkConf().setAppName('Benchmarks')\n",
    "conf.setExecutorEnv('spark.executor.memory', '2g')\n",
    "conf.setExecutorEnv('spark.driver.memory', '30g')\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = sql.SQLContext(sc)\n",
    "\n",
    "data = sqlContext.read.parquet(data_path)\n",
    "print(f\"size: {data.count()} with {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:55:56.284509Z",
     "start_time": "2020-01-25T15:55:55.606125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "read_file took: 0.04250836372375488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04250836372375488"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read/ open\n",
    "def open_file(df=None):\n",
    "    return sqlContext.read.parquet(data_path)\n",
    "\n",
    "benchmark(open_file, df=data, name='read_file', repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:55:57.127265Z",
     "start_time": "2020-01-25T15:55:56.468153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "count took: 0.03326821327209473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03326821327209473"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count(df=None):\n",
    "    return df.count()\n",
    "\n",
    "benchmark(count, df=data, name='count', repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:04.323766Z",
     "start_time": "2020-01-25T15:56:03.662131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "mean took: 0.059554338455200195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.059554338455200195"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean(df):\n",
    "    return df.select(f.mean('fare_amount')).collect()\n",
    "\n",
    "benchmark(mean, df=data, name='mean', repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:10.807896Z",
     "start_time": "2020-01-25T15:56:10.135104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "standard took: 0.0534512996673584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0534512996673584"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_deviation(df):\n",
    "    return df.select(f.stddev('fare_amount')).collect()\n",
    "\n",
    "benchmark(standard_deviation, df=data, name='standard', repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other techonlogies, vaex can return columns, or subset of values to explore lazely, \n",
    "but becouse many of the other tecnologies crashed at this point, we return a scalar instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:12.494654Z",
     "start_time": "2020-01-25T15:56:11.814833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "sum columns mean took: 0.05313467979431152\n"
     ]
    }
   ],
   "source": [
    "def mean_of_sum(df):\n",
    "    return df.select(f.mean(df['fare_amount'] + df['trip_distance'])).collect()\n",
    "\n",
    "benchmark(mean_of_sum, df=data, name='sum columns mean', repetitions=repetitions)\n",
    "benchmarks['sum columns'] =  benchmarks['sum columns mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:13.377614Z",
     "start_time": "2020-01-25T15:56:12.716185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "product columns mean took: 0.057082176208496094\n"
     ]
    }
   ],
   "source": [
    "def mean_of_product(df):\n",
    "    return df.select(f.mean(df['fare_amount'] * df['trip_distance'])).collect()\n",
    "\n",
    "benchmark(mean_of_product, df=data, name='product columns mean', repetitions=repetitions)\n",
    "benchmarks['product columns'] =  benchmarks['product columns mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:14.628167Z",
     "start_time": "2020-01-25T15:56:13.379505Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "arithmetic operation mean took: 0.5879056453704834\n"
     ]
    }
   ],
   "source": [
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df['pickup_longitude']\n",
    "    phi_1 = df['pickup_latitude']\n",
    "    theta_2 = df['dropoff_longitude']\n",
    "    phi_2 = df['dropoff_latitude']\n",
    "    temp = (f.cos(theta_1)*np.pi/180) * (f.cos(theta_2)*np.pi/180) * (f.sin(phi_2-phi_1)/2*np.pi/180)**2\n",
    "    expression = 2 * f.atan2(f.sqrt(temp), f.sqrt(1-temp))\n",
    "    return df.select(f.mean(expression)).collect()\n",
    "\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=data, name='arithmetic operation mean', repetitions=repetitions)\n",
    "benchmarks['arithmetic operation'] =  benchmarks['arithmetic operation mean'] - benchmarks['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:15.477130Z",
     "start_time": "2020-01-25T15:56:14.629976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "value counts took: 0.21796870231628418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21796870231628418"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value_counts(df):\n",
    "    return df.select('fare_amount').distinct().collect()\n",
    "\n",
    "benchmark(value_counts, df=data, name='value counts', repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:16.400223Z",
     "start_time": "2020-01-25T15:56:15.478893Z"
    },
    "code_folding": [
     10
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "groupby statistics took: 0.2846958637237549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2846958637237549"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def groupby_statistics(df):\n",
    "    ret = df.groupby('passenger_count').agg(\n",
    "        f.mean('fare_amount'),\n",
    "        f.stddev('fare_amount'),\n",
    "        f.mean('tip_amount'),\n",
    "        f.stddev('tip_amount')\n",
    "    )\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "\n",
    "benchmark(groupby_statistics, df=data, name='groupby statistics', repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:16.684380Z",
     "start_time": "2020-01-25T15:56:16.401888Z"
    }
   },
   "outputs": [],
   "source": [
    "other = groupby_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:17.796644Z",
     "start_time": "2020-01-25T15:56:16.686007Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "join took: 0.47157740592956543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47157740592956543"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join(df, other):\n",
    "    ret = df.join(other, on = 'passenger_count')\n",
    "    ret.take(3)\n",
    "    return ret\n",
    "\n",
    "benchmark(join, data, name='join', repetitions=repetitions, other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:18.652272Z",
     "start_time": "2020-01-25T15:56:17.798574Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "join count took: 0.2263627052307129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2263627052307129"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_count(df, other):\n",
    "    return df.join(other, on = 'passenger_count').count()\n",
    "\n",
    "benchmark(join_count, data, name='join count', repetitions=repetitions, other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is not build to run on filter data like you would normally, so we will apply the same strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:18.700462Z",
     "start_time": "2020-01-25T15:56:18.654069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare filtered data and deleted 1693 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:48.598427Z",
     "start_time": "2020-01-25T15:56:47.853837Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filter took: 0.10109424591064453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10109424591064453"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_data(df):\n",
    "    expr_filter = (df.pickup_longitude > long_min)  & (df.pickup_longitude < long_max) & \\\n",
    "              (df.pickup_latitude > lat_min)    & (df.pickup_latitude < lat_max) & \\\n",
    "              (df.dropoff_longitude > long_min) & (df.dropoff_longitude < long_max) & \\\n",
    "              (df.dropoff_latitude > lat_min)   & (df.dropoff_latitude < lat_max)\n",
    "    ret = df[expr_filter]\n",
    "    ret.take(3) # evaluate the filter\n",
    "    return ret\n",
    "benchmark(filter_data, data, name='filter', repetitions=repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:56:48.944795Z",
     "start_time": "2020-01-25T15:56:48.797372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned 872 mb\n"
     ]
    }
   ],
   "source": [
    "filterd = filter_data(data)\n",
    "\n",
    "del data\n",
    "print(f\"cleaned {gc.collect()} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T15:57:01.247468Z",
     "start_time": "2020-01-25T15:56:51.302433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filterd count took: 0.09546041488647461\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filterd mean took: 0.17607545852661133\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filtered standard deviation took: 0.18120908737182617\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filtered sum columns mean took: 0.18535757064819336\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filterd product columns mean took: 0.18712377548217773\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filterd arithmetic operation mean took: 0.6530771255493164\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filtered value counts took: 0.34507322311401367\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filtered groupby statistics took: 0.480588436126709\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filtered join took: 0.6496050357818604\n",
      "upload: ../results/spark_1b_mlm52xlarge.csv to s3://vaex-sagemaker-demo/benchmarks/spark_1b_mlm52xlarge_results.csv\n",
      "filtered join count took: 0.45992183685302734\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "benchmark(filter_data, filterd, name='filterd count', repetitions=repetitions)\n",
    "benchmark(mean, filterd, name='filterd mean', repetitions=repetitions)\n",
    "benchmark(standard_deviation, filterd, name='filtered standard deviation', repetitions=repetitions)\n",
    "benchmark(mean_of_sum, filterd, name ='filtered sum columns mean', repetitions=repetitions)\n",
    "benchmarks['filtered sum columns'] =  benchmarks['filtered sum columns mean'] - benchmarks['filterd mean']\n",
    "benchmark(mean_of_product, filterd, name ='filterd product columns mean', repetitions=repetitions)\n",
    "benchmarks['filterd product columns'] = benchmarks['filterd product columns mean'] - benchmarks['filterd mean']\n",
    "benchmark(mean_of_complicated_arithmetic_operation, filterd, name='filterd arithmetic operation mean', repetitions=repetitions)\n",
    "benchmarks['filterd arithmetic operation'] =  benchmarks['filterd arithmetic operation mean'] - benchmarks['filterd mean']\n",
    "benchmark(value_counts, filterd, name ='filtered value counts', repetitions=repetitions)\n",
    "benchmark(groupby_statistics, filterd, name='filtered groupby statistics', repetitions=repetitions)\n",
    "other = groupby_statistics(filterd)\n",
    "benchmark(join, filterd, name='filtered join', repetitions=repetitions, other=other)\n",
    "benchmark(join_count, filterd, name='filtered join count', repetitions=repetitions, other=other)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
