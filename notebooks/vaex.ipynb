{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install vaex-core vaex-hdf5\n",
    "!pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://xdss-public-datasets/demos/taxi_1B.hdf5 to ../datasets/taxi_1B.hdf5g    g \n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://xdss-public-datasets/demos/taxi_1B.hdf5 ../datasets/taxi_1B.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for 1 repetitions\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from src.benchmarks_utils import benchmark, get_results\n",
    "from src.vaex_utils import *\n",
    "from src.config import repetitions\n",
    "\n",
    "name = 'vaex'\n",
    "data_path = '../datasets/taxi_1B.hdf5'\n",
    "results_path = f\"../results/{name}_1b.csv\"\n",
    "benchmarks = {}\n",
    "print(f\"test for {repetitions} repetitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1173057927 with 19 columns\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = read_file(data_path=data_path)\n",
    "data['pickup_hour'] = data.pickup_datetime.dt.hour\n",
    "print(f\"size: {data.shape[0]} with {data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #  vendor_id    pickup_datetime                dropoff_datetime                 passenger_count  payment_type      trip_distance    pickup_longitude    pickup_latitude    rate_code    store_and_fwd_flag    dropoff_longitude    dropoff_latitude    fare_amount    surcharge    mta_tax    tip_amount    tolls_amount    total_amount    pickup_hour    sum    product    complicated\n",
      "  0  VTS          2009-01-04 02:52:00.000000000  2009-01-04 03:02:00.000000000                  1  CASH                       2.63            -73.992             40.7216          nan                   nan             -73.9938             40.6959            8.9          0.5        nan          0                  0            9.4               2    9.9        8.9    0.000127551\n",
      "  1  VTS          2009-01-04 03:31:00.000000000  2009-01-04 03:38:00.000000000                  3  Credit                     4.55            -73.9821            40.7363          nan                   nan             -73.9558             40.768            12.1          0.5        nan          2                  0           14.6               3   15.1       36.3    0.000483058\n",
      "  2  VTS          2009-01-03 15:43:00.000000000  2009-01-03 15:57:00.000000000                  5  Credit                    10.35            -74.0026            40.7397          nan                   nan             -73.87               40.7702           23.7          0          nan          4.74               0           28.44             15   28.7      118.5    0.0023191\n",
      "cleaned 4579 mb\n",
      "Done benchmarks on all data\n",
      "  #  vendor_id    pickup_datetime                dropoff_datetime                 passenger_count  payment_type      trip_distance    pickup_longitude    pickup_latitude    rate_code    store_and_fwd_flag    dropoff_longitude    dropoff_latitude    fare_amount    surcharge    mta_tax    tip_amount    tolls_amount    total_amount    pickup_hour    sum    product    complicated\n",
      "  0  VTS          2009-01-04 02:52:00.000000000  2009-01-04 03:02:00.000000000                  1  CASH                       2.63            -73.992             40.7216          nan                   nan             -73.9938             40.6959            8.9          0.5        nan          0                  0            9.4               2    9.9        8.9    0.000127551\n",
      "  1  VTS          2009-01-04 03:31:00.000000000  2009-01-04 03:38:00.000000000                  3  Credit                     4.55            -73.9821            40.7363          nan                   nan             -73.9558             40.768            12.1          0.5        nan          2                  0           14.6               3   15.1       36.3    0.000483058\n",
      "  2  VTS          2009-01-03 15:43:00.000000000  2009-01-03 15:57:00.000000000                  5  Credit                    10.35            -74.0026            40.7397          nan                   nan             -73.87               40.7702           23.7          0          nan          4.74               0           28.44             15   28.7      118.5    0.0023191\n",
      "Prepare filtered data and deleted 4165 MB\n",
      "Done benchmarks on filterd data\n"
     ]
    }
   ],
   "source": [
    "benchmarks['read_file']= benchmark(read_file, df=data, data_path=data_path, repetitions=repetitions)\n",
    "benchmarks['mean']= benchmark(mean, data, repetitions=repetitions)\n",
    "benchmarks['standard deviation']= benchmark(standard_deviation, data, repetitions=repetitions)\n",
    "benchmarks['sum columns']= benchmark(sum_columns, data, repetitions=repetitions)\n",
    "benchmarks['product columns']= benchmark(product_columns, data, repetitions=repetitions)\n",
    "benchmarks['arithmetic operation']= benchmark(complicated_arithmetic_operation, data, repetitions=repetitions)\n",
    "benchmarks['value counts']= benchmark(value_counts, data, repetitions=repetitions)\n",
    "benchmarks['groupby statistics']= benchmark(groupby_statistics, data, repetitions=repetitions)\n",
    "benchmarks['filter']= benchmark(filter_data, data, repetitions=repetitions)\n",
    "print(f\"cleaned {gc.collect()} mb\")\n",
    "benchmarks['join'] = benchmark(join, data, repetitions=repetitions, other=groupby_statistics(data))\n",
    "print(f\"Done benchmarks on all data\")\n",
    "\n",
    "# filtered\n",
    "filterd = filter_data(data)\n",
    "del data\n",
    "\n",
    "print(f\"Prepare filtered data and deleted {gc.collect()} MB\")\n",
    "benchmarks['filtered mean'] = benchmark(mean, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered standard deviation'] = benchmark(standard_deviation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered sum columns'] = benchmark(sum_columns , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered product_columns'] = benchmark(product_columns , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered complicated arithmetic operation'] = benchmark(complicated_arithmetic_operation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered value counts'] = benchmark(value_counts, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered groupby statistics'] = benchmark(groupby_statistics, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered join'] = benchmark(join, filterd, repetitions=repetitions, other=groupby_statistics(filterd))\n",
    "print(f\"Done benchmarks on filterd data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>read_file</th>\n",
       "      <td>0.009607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.157343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard deviation</th>\n",
       "      <td>2.813296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum columns</th>\n",
       "      <td>0.708558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product columns</th>\n",
       "      <td>0.659668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        vaex\n",
       "read_file           0.009607\n",
       "mean                1.157343\n",
       "standard deviation  2.813296\n",
       "sum columns         0.708558\n",
       "product columns     0.659668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_results(benchmarks, name)\n",
    "results.to_csv(results_path)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../results/vaex_1b.csv to s3://vaex-sagemaker-demo/benchmarks/vaex_1b_results.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp  ../results/vaex_1b.csv s3://vaex-sagemaker-demo/benchmarks/vaex_1b_results.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
