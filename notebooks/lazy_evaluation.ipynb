{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 3.6 karnel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T11:07:58.956738Z",
     "start_time": "2020-05-18T11:07:11.054420Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "python -m pip install -U pip\n",
    "python -m pip install vaex-core==2.0.0a5\n",
    "python -m pip install vaex-hdf5==0.6.0a1 \n",
    "python -m pip install -U numpy \n",
    "python -m pip install -U ipython ipykernel\n",
    "python -m pip install -U datatable\n",
    "python -m pip install dask fsspec>=0.3.3 tqdm pyarrow koalas fastparquet\n",
    "# aws s3 cp --recursive s3://xdss-public-datasets/demos/taxi_1B.sf datasets/taxi_1B.sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:38:01.338863Z",
     "start_time": "2020-05-18T12:38:01.335388Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "def benchmark(f, df, name, **kwargs):    \n",
    "    for i in range(2):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        duration = time.time()-start_time\n",
    "        print(f\"{name}-{i+1}: duration {duration}\")\n",
    "    return duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:38:05.078208Z",
     "start_time": "2020-05-18T12:38:01.926183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1173057927 with 18 columns\n",
      "vaex-1: duration 1.5117080211639404\n",
      "vaex-2: duration 1.4436674118041992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vaex\n",
    "import vaex\n",
    "import numpy as np\n",
    "\n",
    "data = vaex.open('datasets/taxi_1B.hdf5')\n",
    "print(f\"size: {len(data)} with {len(data.columns)} columns\")\n",
    "\n",
    "def vaex_lazy_mean(df):\n",
    "    df['lazy'] = df.fare_amount * df.trip_distance\n",
    "    return df['lazy'].mean()\n",
    "    \n",
    "benchmark(vaex_lazy_mean, df=data, name='vaex')  \n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:38:40.332390Z",
     "start_time": "2020-05-18T12:38:13.210799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:MainThread:root:Found pyspark version \"2.3.4\" installed. pyspark>=2.4.0 is recommended.\n",
      "WARNING:MainThread:root:'ARROW_PRE_0_15_IPC_FORMAT' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=0.15 and pyspark<3.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n",
      "INFO:MainThread:spark:Patching spark automatically. You can disable it by setting SPARK_KOALAS_AUTOPATCH=false in your environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 1173057928 with 18 columns\n",
      "koalas-1: duration 14.04140853881836\n",
      "koalas-2: duration 4.717753887176514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Koalas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import databricks.koalas as ks\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "data = ks.read_parquet('datasets/taxi_parquet/')\n",
    "print(f\"size: {len(data)} with {len(data.columns)} columns\")\n",
    "\n",
    "def koalas_lazy_mean(df):\n",
    "    df['lazy'] = df.fare_amount * df.trip_distance\n",
    "    return df['lazy'].mean()\n",
    "    \n",
    "benchmark(koalas_lazy_mean, df=data, name='koalas')   \n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:39:25.787994Z",
     "start_time": "2020-05-18T12:38:54.328961Z"
    },
    "code_folding": [
     7
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .boolean { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .integer { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .string  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatable-1: duration 15.700656652450562\n",
      "datatable-2: duration 15.407875061035156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datatable\n",
    "import vaex\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "from datatable import f, math\n",
    "\n",
    "# This is a hack to let datatable read hdf5, it currently can't read parquet, multiple files, or a huge csv\n",
    "def read_file(data=None):\n",
    "    vdf = vaex.open('datasets/taxi_1B.hdf5')\n",
    "    columns = {}\n",
    "    for name in vdf.get_column_names():\n",
    "        data = vdf.columns[name]\n",
    "        if data.dtype == str:\n",
    "            pass  # skip strings\n",
    "        elif data.dtype.kind == 'f':\n",
    "            # datatable is picky about <f4 format\n",
    "            columns[name] = data.view(np.float32)\n",
    "        elif data.dtype.kind == 'i':\n",
    "            columns[name] = data\n",
    "        else:\n",
    "            pass  # ignore non int and float\n",
    "    return dt.Frame(**columns)\n",
    "\n",
    "# Load data\n",
    "data = read_file(data=None)\n",
    "\n",
    "def datatable_lazy_mean(df):\n",
    "    df['lazy'] = df[:, f.fare_amount * f.trip_distance]\n",
    "    return df[:, dt.mean(dt.f.lazy)]\n",
    "    \n",
    "benchmark(datatable_lazy_mean, df=data, name='datatable')  \n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:33:51.161614Z",
     "start_time": "2020-05-18T12:33:49.955091Z"
    }
   },
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = dd.read_parquet('datasets/taxi_parquet/*', columns=['vendor_id','fare_amount','trip_distance'])\n",
    "print(f\"size: {len(data.vendor_id)} with {len(data.columns)} columns\")\n",
    "\n",
    "def dask_lazy_mean(df):\n",
    "    df['lazy'] = df.fare_amount * df.trip_distance\n",
    "    return df['lazy'].mean().compute()\n",
    "    \n",
    "benchmark(dask_lazy_mean, df=data, name='dask')  \n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to  conda_tensorflow_p36 karnel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:43:31.260156Z",
     "start_time": "2020-05-18T12:43:25.087964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "python -m pip install turicreate\n",
    "python -m pip install dask[complete]\n",
    "python -m pip install pyarrow==0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:09:28.355228Z",
     "start_time": "2020-05-18T13:09:28.351492Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "def benchmark(f, df, name, **kwargs):    \n",
    "    for i in range(2):\n",
    "        start_time = time.time()\n",
    "        ret = f(df, **kwargs)\n",
    "        duration = time.time()-start_time\n",
    "        print(f\"{name}-{i+1}: duration {duration}\")\n",
    "    return duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:40:49.297622Z",
     "start_time": "2020-05-18T13:09:35.205102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask-1: duration 940.780773639679\n",
      "dask-2: duration 933.2596433162689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3688"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = dd.read_parquet('datasets/taxi_parquet/', engine='pyarrow')\n",
    "print(f\"size: {len(data.vendor_id)} with {len(data.columns)} columns\")\n",
    "\n",
    "def dask_lazy_mean(df):\n",
    "    df['lazy'] = df.fare_amount * df.trip_distance\n",
    "    return df['lazy'].mean().compute()\n",
    "    \n",
    "benchmark(dask_lazy_mean, df=data, name='dask')  \n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-18T13:09:41.030Z"
    }
   },
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "data = tc.SFrame('datasets/taxi_1B.sf')\n",
    "\n",
    "# Turicreate\n",
    "def turi_lazy_mean(df):\n",
    "    df['lazy'] = df['fare_amount'] * df['trip_distance']\n",
    "    return df['lazy'].mean()\n",
    "    \n",
    "benchmark(turi_lazy_mean, df=data, name='turicreate')    \n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
